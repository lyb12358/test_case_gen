#!/usr/bin/env python3
"""
Interface Test Script Generator

This script generates executable interface test scripts based on JSON test cases
generated by the main test case generation script.
"""

import os
import json
import argparse
from datetime import datetime
from dotenv import load_dotenv


def load_test_cases(json_file_path):
    """Load test cases from JSON file"""
    try:
        with open(json_file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        print(f"Error: Could not find JSON file: {json_file_path}")
        return None
    except json.JSONDecodeError as e:
        print(f"Error: Invalid JSON in file: {json_file_path} - {e}")
        return None


def generate_pytest_script(test_cases, output_dir="interface_tests"):
    """
    Generate pytest scripts from test cases

    Args:
        test_cases (dict): Test cases loaded from JSON
        output_dir (str): Directory to save the test scripts

    Returns:
        str: Path to the created test script or None if failed
    """
    try:
        # Create output directory if it doesn't exist
        os.makedirs(output_dir, exist_ok=True)

        # Extract test cases
        cases = test_cases.get("test_cases", [])

        if not cases:
            print("No test cases found in JSON")
            return None

        # Generate filename with functional module of the first test case and timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        functional_module = cases[0].get("functional_module", "interface_tests")

        # If no functional module, use default name
        if not functional_module:
            functional_module = "interface_tests"

        filename = f"test_{functional_module}_{timestamp}.py"
        filepath = os.path.join(output_dir, filename)

        # Generate pytest script content
        script_content = generate_pytest_content(cases)

        # Write to file
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(script_content)

        print(f"Pytest script saved to: {filepath}")
        return filepath

    except Exception as e:
        print(f"Error generating pytest script: {e}")
        return None


def generate_pytest_content(test_cases):
    """Generate pytest script content from test cases"""
    # Script header
    content = '''#!/usr/bin/env python3
"""
Auto-generated interface test script
"""

import pytest
import requests
import json
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Get configuration from environment
API_BASE_URL = os.getenv('API_BASE_URL', 'http://localhost:8080')
API_KEY = os.getenv('API_KEY', 'your-api-key')

# Test data
test_cases = [
'''

    # Add test cases
    for case in test_cases:
        content += f"    {{\n"
        content += f"        'id': '{case.get('id', '')}',\n"
        content += f"        'name': '''{case.get('name', '')}''',\n"
        content += f"        'module': '{case.get('module', '')}',\n"

        # Add preconditions
        preconditions = case.get('preconditions', [])
        if isinstance(preconditions, list):
            content += "        'preconditions': [\n"
            for precondition in preconditions:
                content += f"            '''{precondition}''',\n"
            content += "        ],\n"
        else:
            content += f"        'preconditions': ['''{preconditions}'''],\n"

        # Add steps
        steps = case.get('steps', [])
        content += "        'steps': [\n"
        for step in steps:
            content += f"            '''{step}''',\n"
        content += "        ],\n"

        # Add expected results
        expected_results = case.get('expected_result', [])
        content += "        'expected_results': [\n"
        for result in expected_results:
            content += f"            '''{result}''',\n"
        content += "        ],\n"

        # Add functional module and domain
        content += f"        'functional_module': '{case.get('functional_module', '')}',\n"
        content += f"        'functional_domain': '{case.get('functional_domain', '')}',\n"
        content += "    },\n"

    content += "]\n\n"

    # Add test functions
    content += """
@pytest.fixture(scope="session")
def api_client():
    '''Create API client session'''
    session = requests.Session()
    session.headers.update({
        'Content-Type': 'application/json',
        'Authorization': f'Bearer {API_KEY}'
    })
    return session


def extract_api_call_from_step(step):
    '''Extract API call information from test step'''
    import re
    # Look for JSON in step description
    json_match = re.search(r'\\{.*\\}', step)
    if json_match:
        try:
            api_data = json.loads(json_match.group(0))
            return api_data
        except json.JSONDecodeError:
            pass
    return None


def validate_api_response(response_data, expected_code=None):
    '''Validate API response'''
    if response_data is None:
        return False, "No response data"

    if expected_code:
        actual_code = response_data.get('code', '')
        if actual_code != expected_code:
            return False, f"Expected code {expected_code}, got {actual_code}"

    return True, "Response is valid"


@pytest.mark.parametrize("test_case", test_cases)
def test_interface_functionality(api_client, test_case):
    '''Test interface functionality based on generated test cases'''
    print(f"Running test case: {test_case['id']} - {test_case['name']}")

    # Extract service endpoint from remarks or use default
    endpoint = test_case.get('remarks', '/v1.0/remoteControl/control')
    if endpoint.startswith('/'):
        endpoint = endpoint[1:]  # Remove leading slash if present

    url = f"{API_BASE_URL}/{endpoint}"

    # Process each step in the test case
    steps = test_case.get('steps', [])
    expected_results = test_case.get('expected_result', [])

    api_call_made = False

    for i, step in enumerate(steps):
        # Extract API call information from step
        api_data = extract_api_call_from_step(step)

        if api_data and not api_call_made:
            # This is an API call step, make the actual API request
            print(f"Making API call: {url}")
            print(f"Request data: {api_data}")

            try:
                response = api_client.post(url, json=api_data)
                response_data = response.json() if response.content else None

                print(f"Response status: {response.status_code}")
                print(f"Response data: {response_data}")

                # Validate response based on expected result
                expected_result = expected_results[i] if i < len(expected_results) else ""

                # Check for specific error codes in expected results
                import re
                code_match = re.search(r'"code":\\s*"([\\d]+)"', expected_result)
                expected_code = code_match.group(1) if code_match else None

                is_valid, message = validate_api_response(response_data, expected_code)
                assert is_valid, f"API response validation failed: {message}"

                # For successful calls, check that we got a session ID
                if response.status_code == 200 and not expected_code:
                    assert response_data and 'data' in response_data and 'sessionId' in response_data['data'], \
                        "Expected sessionId in response for successful API call"

                api_call_made = True

            except Exception as e:
                # For negative test cases (error conditions), we might expect exceptions
                if "参数不正确" in expected_result or "没有车辆使用权" in expected_result:
                    # This is an expected error case, so the exception might be OK
                    print(f"Expected error occurred: {e}")
                else:
                    raise e

        # For non-API steps, just print the step description
        elif not api_call_made:
            print(f"Step {i+1}: {step}")

    # If no API call was made, validate the test case structure
    if not api_call_made:
        assert test_case['id'], "Test case ID is required"
        assert test_case['name'], "Test case name is required"
        assert test_case['steps'], "Test case steps are required"
        assert test_case['expected_results'], "Test case expected results are required"

        # Validate that steps and expected results have the same length
        assert len(test_case['steps']) == len(test_case['expected_results']), \\
            "Steps and expected results must have the same length"

    print(f"Test case {test_case['id']} completed")


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
"""

    return content


def main():
    """Main function to generate interface test scripts"""
    # Load environment variables
    load_dotenv()

    # Get JSON file path from environment
    json_file_path = os.getenv('JSON_FILE_PATH')

    if not json_file_path:
        print("Error: JSON_FILE_PATH not found in environment variables")
        return

    # Check if file exists
    if not os.path.exists(json_file_path):
        print(f"Error: JSON file not found at {json_file_path}")
        return

    # Output directory for test scripts
    interface_tests_dir = "interface_tests"

    # Load test cases
    test_cases = load_test_cases(json_file_path)
    if not test_cases:
        return

    # Generate pytest script
    print("=== Generating Interface Test Scripts ===")
    script_path = generate_pytest_script(test_cases, interface_tests_dir)
    if script_path:
        print(f"Interface test script created successfully: {script_path}")
    else:
        print("Failed to create interface test script.")


if __name__ == "__main__":
    main()