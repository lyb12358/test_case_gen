# -*- coding: utf-8 -*-
"""
Unified test case API endpoints.
Combines test point and test case management in a single unified API.
"""

from typing import Optional, List, Dict, Any, Tuple
from fastapi import APIRouter, Depends, HTTPException, Query, BackgroundTasks
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_, func, desc, asc
import json
import uuid
import logging
import time
from datetime import datetime
from pydantic import BaseModel

from ..database.models import (
    UnifiedTestCase, Project,
    BusinessType, GenerationJob, UnifiedTestCaseStatus, UnifiedTestCaseStage as DatabaseUnifiedTestCaseStage
)
from ..models.unified_test_case import (
    UnifiedTestCaseCreate, UnifiedTestCaseUpdate, UnifiedTestCaseResponse,
    UnifiedTestCaseListResponse, UnifiedTestCaseFilter, UnifiedTestCaseStatistics,
    UnifiedTestCaseBatchOperation, UnifiedTestCaseBatchResponse,
    UnifiedTestCaseGenerationRequest, UnifiedTestCaseGenerationResponse,
    UnifiedTestCaseStage as SchemaUnifiedTestCaseStage, UnifiedTestCaseDeleteResponse
)

from .dependencies import get_db
from ..utils.business_type_validator import validate_business_type_or_400
# TestPointGenerator removed - using unified generation system
from ..core.test_case_generator import TestCaseGenerator
from ..services.sync_transaction_manager import SyncTransactionManager
from ..utils.config import Config

# Import the enhanced data validator and repairer
try:
    from ..utils.data_validator_repairer import DataValidatorRepairer
    from ..core.json_extractor import JSONExtractor
except ImportError:
    # Fallback for different import paths
    import sys
    import os
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(current_dir)
    utils_dir = os.path.join(parent_dir, 'utils')
    core_dir = os.path.join(parent_dir, 'core')

    if utils_dir not in sys.path:
        sys.path.append(utils_dir)
    if core_dir not in sys.path:
        sys.path.append(core_dir)

    from data_validator_repairer import DataValidatorRepairer
    from json_extractor import JSONExtractor

router = APIRouter(prefix="/unified-test-cases", tags=["unified-test-cases"])

logger = logging.getLogger(__name__)

def _get_business_type_value(business_type):
    """
    å®‰å…¨åœ°èŽ·å–business_typeçš„å€¼ï¼ˆçŽ°åœ¨åªå¤„ç†å­—ç¬¦ä¸²ç±»åž‹ï¼‰
    """
    return business_type  # business_type çŽ°åœ¨ç›´æŽ¥æ˜¯å­—ç¬¦ä¸²





# Implementation function
async def get_unified_test_cases_impl(
    filter_params: UnifiedTestCaseFilter,
    db: Session
) -> UnifiedTestCaseListResponse:
    """
    èŽ·å–ç»Ÿä¸€æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨çš„å…·ä½“å®žçŽ°
    æ”¯æŒæŒ‰é˜¶æ®µã€çŠ¶æ€ã€ä¸šåŠ¡ç±»åž‹ç­‰è¿‡æ»¤
    """
    try:
        # æž„å»ºæŸ¥è¯¢
        query = db.query(UnifiedTestCase)

        # åº”ç”¨è¿‡æ»¤æ¡ä»¶
        if filter_params.project_id:
            query = query.filter(UnifiedTestCase.project_id == filter_params.project_id)

        if filter_params.business_type:
            query = query.filter(UnifiedTestCase.business_type == filter_params.business_type)

        if filter_params.status:
            query = query.filter(UnifiedTestCase.status == filter_params.status.value)

        if filter_params.priority:
            query = query.filter(UnifiedTestCase.priority == filter_params.priority)

        if filter_params.keyword:
            keyword = f"%{filter_params.keyword}%"
            query = query.filter(
                or_(
                    UnifiedTestCase.name.ilike(keyword),
                    UnifiedTestCase.description.ilike(keyword),
                    UnifiedTestCase.test_case_id.ilike(keyword)
                )
            )

  
        # æŒ‰é˜¶æ®µè¿‡æ»¤
        if filter_params.stage == SchemaUnifiedTestCaseStage.TEST_POINT:
            query = query.filter(
                UnifiedTestCase.stage == DatabaseUnifiedTestCaseStage.test_point
            )
        elif filter_params.stage == SchemaUnifiedTestCaseStage.TEST_CASE:
            query = query.filter(
                UnifiedTestCase.stage == DatabaseUnifiedTestCaseStage.test_case
            )

        # èŽ·å–æ€»æ•°
        total = query.count()

        # åº”ç”¨æŽ’åº
        sort_column = getattr(UnifiedTestCase, filter_params.sort_by, UnifiedTestCase.id)
        if filter_params.sort_order == "desc":
            query = query.order_by(desc(sort_column))
        else:
            query = query.order_by(asc(sort_column))

        # åº”ç”¨åˆ†é¡µ
        offset = (filter_params.page - 1) * filter_params.size
        test_cases = query.offset(offset).limit(filter_params.size).all()

        # è½¬æ¢ä¸ºå“åº”æ¨¡åž‹
        test_case_responses = []
        for test_case in test_cases:
            # Convert database stage enum to schema stage enum
            stage = (
                SchemaUnifiedTestCaseStage.TEST_POINT
                if test_case.is_test_point_stage()
                else SchemaUnifiedTestCaseStage.TEST_CASE
            )

            # å‰ç½®æ¡ä»¶çŽ°åœ¨ç›´æŽ¥è¿”å›žå­—ç¬¦ä¸²æ ¼å¼ï¼Œç”±å‰ç«¯è´Ÿè´£è§£æž

            response_data = UnifiedTestCaseResponse(
                id=test_case.id,
                project_id=test_case.project_id,
                business_type=_get_business_type_value(test_case.business_type),
                case_id=test_case.test_case_id,
                test_case_id=test_case.test_case_id,
                name=test_case.name,
                description=test_case.description,
                priority=test_case.priority,
                status=test_case.status,
                stage=stage,
                module=test_case.module,
                functional_module=test_case.functional_module,
                functional_domain=test_case.functional_domain,
                preconditions=test_case.preconditions,  # ç›´æŽ¥è¿”å›žå­—ç¬¦ä¸²æ ¼å¼
                steps=_merge_steps_with_expected_results(_parse_steps_field(test_case.steps), test_case.expected_result),
                expected_result=test_case.expected_result,
                remarks=test_case.remarks,
                generation_job_id=test_case.generation_job_id,
                entity_order=test_case.entity_order,
                created_at=test_case.created_at,
                updated_at=test_case.updated_at
            )
            test_case_responses.append(response_data)

        # è®¡ç®—æ€»é¡µæ•°
        pages = (total + filter_params.size - 1) // filter_params.size

        return UnifiedTestCaseListResponse(
            items=test_case_responses,
            total=total,
            page=filter_params.page,
            size=filter_params.size,
            pages=pages
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"èŽ·å–æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨å¤±è´¥: {str(e)}")


# API endpoints with both path variations
@router.get("/", response_model=UnifiedTestCaseListResponse)
async def get_unified_test_cases(
    page: int = Query(1, ge=1, description="é¡µç "),
    size: int = Query(20, ge=1, le=100, description="æ¯é¡µå¤§å°"),
    project_id: Optional[int] = Query(None, description="é¡¹ç›®ID"),
    business_type: Optional[str] = Query(None, description="ä¸šåŠ¡ç±»åž‹"),
    status: Optional[UnifiedTestCaseStatus] = Query(None, description="çŠ¶æ€"),
    stage: Optional[SchemaUnifiedTestCaseStage] = Query(None, description="é˜¶æ®µ"),
    priority: Optional[str] = Query(None, pattern="^(low|medium|high)$", description="ä¼˜å…ˆçº§"),
    keyword: Optional[str] = Query(None, description="å…³é”®è¯æœç´¢"),
    sort_by: str = Query("id", description="æŽ’åºå­—æ®µ"),
    sort_order: str = Query("desc", pattern="^(asc|desc)$", description="æŽ’åºæ–¹å‘"),
    db: Session = Depends(get_db)
):
    """
    èŽ·å–ç»Ÿä¸€æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
    """
    # æ‰‹åŠ¨æž„å»ºè¿‡æ»¤å™¨å¯¹è±¡
    filter_params = UnifiedTestCaseFilter(
        page=page,
        size=size,
        project_id=project_id,
        business_type=business_type,
        status=status,
        stage=stage,
        priority=priority,
        keyword=keyword,
        sort_by=sort_by,
        sort_order=sort_order
    )
    return await get_unified_test_cases_impl(filter_params, db)


@router.post("/generate-sync", response_model=UnifiedTestCaseGenerationResponse)
async def generate_unified_sync(
    request: UnifiedTestCaseGenerationRequest,
    db: Session = Depends(get_db)
):
    """
    Synchronous unified generation endpoint for debugging and testing.
    Directly executes generation and returns results without background tasks.
    - test_points_only: Generate test points for a business type
    - test_cases_only: Generate test cases from existing test points
    """
    import time
    from datetime import datetime
    from ..database.models import GenerationJob, JobStatus, BusinessTypeConfig

    logger.info(f"ðŸš€ Starting synchronous generation: mode={request.generation_mode}, business_type={request.business_type}")

    try:
        # Validate business type
        business_config = db.query(BusinessTypeConfig).filter(
            BusinessTypeConfig.code == request.business_type.upper(),
            BusinessTypeConfig.is_active == True
        ).first()

        if not business_config:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸šåŠ¡ç±»åž‹ '{request.business_type}' ä¸å­˜åœ¨æˆ–æœªæ¿€æ´»"
            )

        # Validate project exists
        project = db.query(Project).filter(Project.id == request.project_id).first()
        if not project:
            raise HTTPException(status_code=400, detail="é¡¹ç›®ä¸å­˜åœ¨")

        # Generate task ID for tracking (even though we're not using background tasks)
        task_id = str(uuid.uuid4())
        start_time = time.time()

        logger.info(f"Task {task_id} started at {datetime.now()}")

        if request.generation_mode == "test_points_only":
            # Execute synchronous test points generation
            logger.info(f"Executing synchronous test points generation for task {task_id}")
            result = await _generate_test_points_sync_unified(
                task_id=task_id,
                business_type=request.business_type.upper(),
                project_id=request.project_id,
                additional_context=request.additional_context,
                db=db
            )
            generation_time = time.time() - start_time

            return UnifiedTestCaseGenerationResponse(
                generation_job_id=task_id,
                status="completed",
                test_points_generated=result['test_points_generated'],
                test_cases_generated=0,
                unified_test_cases=result['unified_test_cases'],
                generation_time=generation_time,
                message=f"åŒæ­¥ç”Ÿæˆå®Œæˆ: {result['test_points_generated']} ä¸ªæµ‹è¯•ç‚¹"
            )

        elif request.generation_mode == "test_cases_only":
            # Validate test points exist
            if not request.test_point_ids or len(request.test_point_ids) == 0:
                raise HTTPException(
                    status_code=400,
                    detail="test_cases_onlyæ¨¡å¼éœ€è¦æä¾›test_point_ids"
                )

            test_points = db.query(UnifiedTestCase).filter(
                UnifiedTestCase.id.in_(request.test_point_ids),
                UnifiedTestCase.business_type == request.business_type.upper(),
                UnifiedTestCase.project_id == request.project_id,
                # Fix: Remove strict steps.is_(None) requirement to allow partially updated test points
                or_(UnifiedTestCase.steps.is_(None), UnifiedTestCase.stage == DatabaseUnifiedTestCaseStage.TEST_POINT)
            ).all()

            if not test_points:
                raise HTTPException(
                    status_code=400,
                    detail="æœªæ‰¾åˆ°æŒ‡å®šçš„æµ‹è¯•ç‚¹"
                )

            # Execute synchronous test cases generation
            logger.info(f"Executing synchronous test cases generation for task {task_id}")
            result = await _generate_test_cases_sync_unified(
                task_id=task_id,
                business_type=request.business_type.upper(),
                project_id=request.project_id,
                test_point_ids=request.test_point_ids,
                additional_context=request.additional_context,
                db=db
            )
            generation_time = time.time() - start_time

            return UnifiedTestCaseGenerationResponse(
                generation_job_id=task_id,
                status="completed",
                test_points_generated=0,
                test_cases_generated=result['test_cases_generated'],
                unified_test_cases=result['unified_test_cases'],
                generation_time=generation_time,
                message=f"åŒæ­¥ç”Ÿæˆå®Œæˆ: {result['test_cases_generated']} ä¸ªæµ‹è¯•ç”¨ä¾‹"
            )
        else:
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„ç”Ÿæˆæ¨¡å¼: {request.generation_mode}")

    except HTTPException as e:
        logger.error(f"HTTP Exception in synchronous generation: {str(e)}")
        raise
    except Exception as e:
        logger.error(f"Error in synchronous generation: {str(e)}", exc_info=True)
        error_message = str(e)
        generation_time = time.time() - start_time if 'start_time' in locals() else 0

        raise HTTPException(
            status_code=500,
            detail=f"åŒæ­¥ç”Ÿæˆå¤±è´¥: {error_message}"
        )


@router.get("/{test_case_id}", response_model=UnifiedTestCaseResponse)
async def get_unified_test_case(
    test_case_id: int,
    db: Session = Depends(get_db)
):
    """èŽ·å–å•ä¸ªç»Ÿä¸€æµ‹è¯•ç”¨ä¾‹è¯¦æƒ…"""
    try:
        logger.info(f"ðŸ” GET request for test_case_id: {test_case_id}")
        test_case = db.query(UnifiedTestCase).filter(UnifiedTestCase.id == test_case_id).first()

        if not test_case:
            raise HTTPException(status_code=404, detail="æµ‹è¯•ç”¨ä¾‹ä¸å­˜åœ¨")

        # è®°å½•æ•°æ®åº“ä¸­çš„åŽŸå§‹æ•°æ®
        logger.info(f"ðŸ“‹ Database raw steps: {test_case.steps}")
        logger.info(f"ðŸŽ¯ Database raw expected_result: {test_case.expected_result}")
        logger.info(f"ðŸ“‹ Database raw preconditions: {test_case.preconditions}")

        # Convert database stage enum to schema stage enum
        stage = (
            SchemaUnifiedTestCaseStage.TEST_POINT
            if test_case.is_test_point_stage()
            else SchemaUnifiedTestCaseStage.TEST_CASE
        )

        # è§£æžstepså­—æ®µï¼Œä¼˜å…ˆä½¿ç”¨åµŒå…¥çš„é¢„æœŸç»“æžœ
        parsed_steps = _parse_steps_field(test_case.steps)
        logger.info(f"ðŸ“‹ Parsed steps: {parsed_steps}")
        logger.info(f"ðŸ“‹ Parsed steps count: {len(parsed_steps) if isinstance(parsed_steps, list) else 'N/A'}")

        # åˆå¹¶æ­¥éª¤å’Œé¢„æœŸç»“æžœï¼ˆå¦‚æžœstepsä¸­æ²¡æœ‰expectedå­—æ®µï¼‰
        merged_steps = _merge_steps_with_expected_results(parsed_steps, test_case.expected_result)

        # è§£æžpreconditionsä¸ºæ•°ç»„æ ¼å¼
        if test_case.preconditions:
            try:
                final_preconditions = json.loads(test_case.preconditions)
                if not isinstance(final_preconditions, list):
                    final_preconditions = [test_case.preconditions]
            except (json.JSONDecodeError, Exception):
                final_preconditions = [test_case.preconditions]
        else:
            final_preconditions = []

        # è®°å½•æœ€ç»ˆè¿”å›žçš„æ•°æ®
        logger.info(f"ðŸ“¤ Final steps being returned: {merged_steps}")
        logger.info(f"ðŸ“¤ Final steps count: {len(merged_steps) if isinstance(merged_steps, list) else 'N/A'}")
        logger.info(f"ðŸŽ¯ Database expected_result: {test_case.expected_result}")

        # è¯¦ç»†æ£€æŸ¥stepsä¸­æ¯ä¸ªæ­¥éª¤çš„expectedå­—æ®µ
        if isinstance(merged_steps, list):
            for i, step in enumerate(merged_steps):
                if isinstance(step, dict) and 'expected' in step:
                    logger.info(f"ðŸ“‹ Step {i+1} expected: {step['expected']}")
                else:
                    logger.warning(f"âš ï¸ Step {i+1} missing expected field: {step}")

        logger.info(f"âœ… GET request completed for test_case_id: {test_case_id}")

        return UnifiedTestCaseResponse(
            id=test_case.id,
            project_id=test_case.project_id,
            business_type=_get_business_type_value(test_case.business_type),
            test_case_id=test_case.test_case_id,
            case_id=test_case.test_case_id,
            name=test_case.name,
            description=test_case.description,
            priority=test_case.priority,
            status=test_case.status,
            stage=stage,
            module=test_case.module,
            functional_module=test_case.functional_module,
            functional_domain=test_case.functional_domain,
            preconditions=test_case.preconditions,  # ç›´æŽ¥è¿”å›žå­—ç¬¦ä¸²æ ¼å¼
            steps=merged_steps,
            expected_result=test_case.expected_result,
                        remarks=test_case.remarks,
            generation_job_id=test_case.generation_job_id,
            entity_order=test_case.entity_order,
            created_at=test_case.created_at,
            updated_at=test_case.updated_at
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"èŽ·å–æµ‹è¯•ç”¨ä¾‹è¯¦æƒ…å¤±è´¥: {str(e)}")


@router.post("/", response_model=UnifiedTestCaseResponse)
async def create_unified_test_case(
    test_case_data: UnifiedTestCaseCreate,
    db: Session = Depends(get_db)
):
    """åˆ›å»ºæ–°çš„ç»Ÿä¸€æµ‹è¯•ç”¨ä¾‹"""
    try:
        # éªŒè¯é¡¹ç›®å­˜åœ¨
        from ..database.models import Project
        project = db.query(Project).filter(Project.id == test_case_data.project_id).first()
        if not project:
            raise HTTPException(status_code=400, detail="é¡¹ç›®ä¸å­˜åœ¨")

  
        # æ£€æŸ¥test_case_idåœ¨é¡¹ç›®å†…çš„å”¯ä¸€æ€§
        existing_case = db.query(UnifiedTestCase).filter(
            and_(
                UnifiedTestCase.project_id == test_case_data.project_id,
                UnifiedTestCase.business_type == test_case_data.business_type,
                UnifiedTestCase.test_case_id == test_case_data.test_case_id
            )
        ).first()

        if existing_case:
            raise HTTPException(status_code=400, detail="æµ‹è¯•ç”¨ä¾‹IDåœ¨å½“å‰é¡¹ç›®å’Œä¸šåŠ¡ç±»åž‹ä¸­å·²å­˜åœ¨")

        # Check for business-scoped name uniqueness
        sync_manager = SyncTransactionManager(db)
        if not sync_manager.validate_business_uniqueness(
            business_type=test_case_data.business_type,
            name=test_case_data.name,
            entity_type='test_case'
        ):
            raise HTTPException(
                status_code=400,
                detail=f"Test case name '{test_case_data.name}' already exists in business type '{test_case_data.business_type}'"
            )

        # æ ¹æ®æ˜¯å¦æœ‰æ‰§è¡Œæ­¥éª¤ç¡®å®šstage
        has_steps = test_case_data.steps and len(test_case_data.steps) > 0
        has_preconditions = test_case_data.preconditions and len(test_case_data.preconditions) > 0
        stage = DatabaseUnifiedTestCaseStage.test_case if (has_steps or has_preconditions) else DatabaseUnifiedTestCaseStage.test_point

        # Validate business type using database-driven validation
        validate_business_type_or_400(
            db=db,
            business_type=test_case_data.business_type,
            project_id=test_case_data.project_id
        )

        db_test_case = UnifiedTestCase(
            project_id=test_case_data.project_id,
            business_type=test_case_data.business_type.upper(),  # Store as uppercase string
            test_case_id=test_case_data.test_case_id,
            name=test_case_data.name,
            description=test_case_data.description,
            priority=test_case_data.priority,
            status=test_case_data.status.value if test_case_data.status else UnifiedTestCaseStatus.DRAFT,
            stage=stage,
            module=test_case_data.module,
            functional_module=test_case_data.functional_module,
            functional_domain=test_case_data.functional_domain,
            preconditions=test_case_data.preconditions,  # çŽ°åœ¨ç›´æŽ¥æ˜¯å­—ç¬¦ä¸²ï¼Œä¸éœ€è¦JSONåºåˆ—åŒ–
            steps=json.dumps(test_case_data.steps, ensure_ascii=False) if test_case_data.steps else None,
            remarks=test_case_data.remarks,
            entity_order=test_case_data.entity_order,
            created_at=datetime.now(),
            updated_at=datetime.now()
        )

        db.add(db_test_case)
        db.commit()
        db.refresh(db_test_case)

        # Convert database stage enum to schema stage enum
        stage = (
            SchemaUnifiedTestCaseStage.TEST_POINT
            if db_test_case.is_test_point_stage()
            else SchemaUnifiedTestCaseStage.TEST_CASE
        )

        # å‰ç½®æ¡ä»¶çŽ°åœ¨ç›´æŽ¥è¿”å›žå­—ç¬¦ä¸²æ ¼å¼ï¼Œç”±å‰ç«¯è´Ÿè´£è§£æž

        return UnifiedTestCaseResponse(
            id=db_test_case.id,
            project_id=db_test_case.project_id,
            business_type=_get_business_type_value(db_test_case.business_type),
            case_id=db_test_case.test_case_id,
            test_case_id=db_test_case.test_case_id,
            name=db_test_case.name,
            description=db_test_case.description,
            priority=db_test_case.priority,
            status=db_test_case.status,
            stage=stage,
            module=db_test_case.module,
            functional_module=db_test_case.functional_module,
            functional_domain=db_test_case.functional_domain,
            preconditions=db_test_case.preconditions,  # ç›´æŽ¥è¿”å›žå­—ç¬¦ä¸²æ ¼å¼
            steps=_parse_json_field(db_test_case.steps),
            remarks=db_test_case.remarks,
            generation_job_id=db_test_case.generation_job_id,
            entity_order=db_test_case.entity_order,
            created_at=db_test_case.created_at,
            updated_at=db_test_case.updated_at
        )

    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(e)}")


@router.put("/{test_case_id}", response_model=UnifiedTestCaseResponse)
async def update_unified_test_case(
    test_case_id: int,
    test_case_data: UnifiedTestCaseUpdate,
    db: Session = Depends(get_db)
):
    """æ›´æ–°ç»Ÿä¸€æµ‹è¯•ç”¨ä¾‹"""
    try:
        # æ·»åŠ è¯·æ±‚å…¥å£è°ƒè¯•æ—¥å¿—
        logger.info(f"ðŸš€ PUT request received for test_case_id: {test_case_id}")
        raw_data = test_case_data.dict(exclude_unset=True)
        logger.info(f"ðŸ“‹ Raw update data keys: {list(raw_data.keys())}")

        # è¯¦ç»†è®°å½•stepså’Œexpected_resultå­—æ®µ
        if 'steps' in raw_data:
            logger.info(f"ðŸ“‹ Steps in raw data: type={type(raw_data['steps'])}, count={len(raw_data['steps']) if isinstance(raw_data['steps'], list) else 'N/A'}")
            if isinstance(raw_data['steps'], list) and len(raw_data['steps']) > 0:
                logger.info(f"ðŸ“‹ First step sample: {raw_data['steps'][0]}")

        if 'expected_result' in raw_data:
            logger.info(f"ðŸŽ¯ Expected_result in raw data: type={type(raw_data['expected_result'])}, value={raw_data['expected_result']}")
        else:
            logger.info("â„¹ï¸ Expected_result not provided in update (will keep existing value)")

        if 'preconditions' in raw_data:
            logger.info(f"ðŸ“‹ Preconditions in raw data: type={type(raw_data['preconditions'])}, value={raw_data['preconditions']}")

  
        test_case = db.query(UnifiedTestCase).filter(UnifiedTestCase.id == test_case_id).first()

        if not test_case:
            raise HTTPException(status_code=404, detail="æµ‹è¯•ç”¨ä¾‹ä¸å­˜åœ¨")

        # æ›´æ–°å­—æ®µ
        update_data = test_case_data.dict(exclude_unset=True)

        # ðŸ” Debug: Log preconditions after validation processing
        if 'preconditions' in update_data:
            logger.info(f"ðŸ” Debug: preconditions processed in update_data: {update_data.get('preconditions', 'NOT_FOUND')}")

        # å¤„ç†æžšä¸¾å€¼
        if 'status' in update_data:
            update_data['status'] = update_data['status'].value

        # å¤„ç†stageæžšä¸¾å€¼
        if 'stage' in update_data:
            if update_data['stage'] == SchemaUnifiedTestCaseStage.TEST_POINT:
                update_data['stage'] = DatabaseUnifiedTestCaseStage.test_point
            elif update_data['stage'] == SchemaUnifiedTestCaseStage.TEST_CASE:
                update_data['stage'] = DatabaseUnifiedTestCaseStage.test_case
            else:
                logger.warning(f"Unknown stage value: {update_data['stage']}")

        # Validate business_type if present in update data
        if 'business_type' in update_data:
            logger.info(f"Validating business_type: '{update_data['business_type']}'")
            validate_business_type_or_400(
                db=db,
                business_type=update_data['business_type'],
                project_id=db_test_case.project_id
            )
            # Store as uppercase string
            update_data['business_type'] = update_data['business_type'].upper()
            logger.info(f"Validated business_type: {update_data['business_type']}")

        # å¤„ç†JSONå­—æ®µ - ç®€åŒ–å¤„ç†
        json_fields = ['steps', 'expected_result']  # ç§»é™¤preconditionsï¼Œå› ä¸ºçŽ°åœ¨æ˜¯ç®€å•çš„å­—ç¬¦ä¸²å­—æ®µ
        for field in json_fields:
            if field in update_data:
                original_value = update_data[field]

                # ç‰¹æ®Šå¤„ç†stepså­—æ®µï¼Œç¡®ä¿é¢„æœŸç»“æžœæ­£ç¡®åµŒå…¥
                if field == 'steps' and isinstance(original_value, list):
                    # éªŒè¯stepsä¸­çš„expectedå­—æ®µ
                    processed_steps = []
                    for i, step in enumerate(original_value):
                        if isinstance(step, dict):
                            processed_step = {
                                'step_number': step.get('step_number', i + 1),
                                'action': step.get('action', step.get('description', '')),
                                'expected': step.get('expected', '')
                            }
                            processed_steps.append(processed_step)
                            logger.info(f"ðŸ“‹ Processed step {i+1}: action='{processed_step['action'][:50]}...', expected='{processed_step['expected'][:50]}...'")
                        else:
                            logger.warning(f"âš ï¸ Invalid step format at index {i}: {step}")

                    # ä½¿ç”¨å¤„ç†åŽçš„steps
                    update_data[field] = _serialize_json_field(processed_steps)
                    logger.info(f"ðŸ“‹ Steps processed and serialized: {len(processed_steps)} steps")

                    # å½“stepsåŒ…å«expectedå­—æ®µæ—¶ï¼Œç§»é™¤å•ç‹¬çš„expected_resultå­—æ®µï¼Œé¿å…æ•°æ®é‡å¤
                    if 'expected_result' in update_data and any(step.get('expected') for step in processed_steps):
                        logger.info("ðŸ—‘ï¸ Removing duplicate expected_result field since steps contain expected data")
                        del update_data['expected_result']
                else:
                    # å…¶ä»–JSONå­—æ®µæ­£å¸¸å¤„ç†
                    update_data[field] = _serialize_json_field(update_data[field])

                logger.info(f"ðŸ”§ JSON field {field} serialized: {type(original_value)} -> {type(update_data.get(field))}")
                logger.info(f"ðŸ”§ {field} length: {len(str(update_data.get(field)))}")

        logger.info(f"Final update_data keys: {list(update_data.keys())}")

        # æ›´æ–°æ—¶é—´æˆ³
        update_data['updated_at'] = datetime.now()

        # Track if name is being updated for sync
        name_updated = False
        new_name = None
        if 'name' in update_data and update_data['name'] != test_case.name:
            # Check for business-scoped name uniqueness before updating
            sync_manager = SyncTransactionManager(db)
            # ä¼˜å…ˆä½¿ç”¨æ›´æ–°åŽçš„æ–°ä¸šåŠ¡ç±»åž‹ï¼ˆç¡®ä¿è½¬æ¢ä¸ºå­—ç¬¦ä¸²ç”¨äºŽéªŒè¯ï¼‰
            new_business_type = update_data.get('business_type', test_case.business_type)
            # å¦‚æžœæ˜¯æžšä¸¾ç±»åž‹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²å€¼
            if hasattr(new_business_type, 'value'):
                new_business_type = new_business_type.value
            if not sync_manager.validate_business_uniqueness(
                business_type=new_business_type,
                name=update_data['name'],
                entity_type='test_case',
                exclude_id=test_case.id
            ):
                raise HTTPException(
                    status_code=400,
                    detail=f"Test case name '{update_data['name']}' already exists in business type '{new_business_type}'"
                )

            name_updated = True
            new_name = update_data['name']
            logger.info(f"Test case name update detected: '{test_case.name}' -> '{new_name}' (test_case_id: {test_case_id})")

        # Apply updates to the test case
        for field, value in update_data.items():
            # ç‰¹æ®Šå¤„ç†preconditionså­—æ®µï¼Œå°†æ•°ç»„è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²å­˜å‚¨åˆ°æ•°æ®åº“
            if field == 'preconditions' and isinstance(value, list):
                setattr(test_case, field, json.dumps(value, ensure_ascii=False))
                logger.info(f"ðŸ“‹ Preconditions array converted to JSON string for database storage: {len(value)} items")
            else:
                setattr(test_case, field, value)

        # æ·»åŠ æ•°æ®åº“æ“ä½œçš„é”™è¯¯å¤„ç†
        try:
            db.commit()
            logger.info(f"Successfully updated test case {test_case_id} with data: {update_data}")
            db.refresh(test_case)
        except Exception as db_error:
            db.rollback()
            logger.error(f"Database error when updating test case {test_case_id}: {str(db_error)}")
            raise HTTPException(
                status_code=500,
                detail=f"æ•°æ®åº“æ›´æ–°å¤±è´¥: {str(db_error)}"
            )

        # Convert database stage enum to schema stage enum
        stage = (
            SchemaUnifiedTestCaseStage.TEST_POINT
            if test_case.is_test_point_stage()
            else SchemaUnifiedTestCaseStage.TEST_CASE
        )

        # è§£æžå¹¶åˆå¹¶æ­¥éª¤å’Œé¢„æœŸç»“æžœç”¨äºŽè¿”å›ž
        parsed_steps = _parse_steps_field(test_case.steps)
        merged_steps_for_return = _merge_steps_with_expected_results(parsed_steps, test_case.expected_result)

        # è§£æžpreconditionsä¸ºæ•°ç»„æ ¼å¼ç”¨äºŽè¿”å›ž
        if test_case.preconditions:
            try:
                final_preconditions = json.loads(test_case.preconditions)
                if not isinstance(final_preconditions, list):
                    final_preconditions = [test_case.preconditions]
            except (json.JSONDecodeError, Exception):
                final_preconditions = [test_case.preconditions]
        else:
            final_preconditions = []

        return UnifiedTestCaseResponse(
            id=test_case.id,
            project_id=test_case.project_id,
            business_type=_get_business_type_value(test_case.business_type),
            test_case_id=test_case.test_case_id,
            case_id=test_case.test_case_id,
            name=test_case.name,
            description=test_case.description,
            priority=test_case.priority,
            status=test_case.status,
            stage=stage,
            module=test_case.module,
            functional_module=test_case.functional_module,
            functional_domain=test_case.functional_domain,
            preconditions=test_case.preconditions,  # ç›´æŽ¥è¿”å›žå­—ç¬¦ä¸²æ ¼å¼
            steps=merged_steps_for_return,  # ä½¿ç”¨åˆå¹¶åŽçš„æ­¥éª¤æ•°æ®
            expected_result=test_case.expected_result,
                        remarks=test_case.remarks,
            generation_job_id=test_case.generation_job_id,
            entity_order=test_case.entity_order,
            created_at=test_case.created_at,
            updated_at=test_case.updated_at
        )

    except HTTPException:
        raise
    except Exception as e:
        error_str = str(e).lower()
        db.rollback()
        logger.error(f"Failed to update test case {test_case_id}: {str(e)}", exc_info=True)

        # æ ¹æ®é”™è¯¯ç±»åž‹è¿”å›žä¸åŒçš„çŠ¶æ€ç 
        if "integrity" in error_str or "constraint" in error_str:
            raise HTTPException(status_code=400, detail=f"æ•°æ®å®Œæ•´æ€§é”™è¯¯: {str(e)}")
        elif "timeout" in error_str or "connection" in error_str:
            raise HTTPException(status_code=503, detail=f"æ•°æ®åº“è¿žæŽ¥è¶…æ—¶: {str(e)}")
        elif "not found" in error_str:
            raise HTTPException(status_code=404, detail=f"æµ‹è¯•ç”¨ä¾‹ä¸å­˜åœ¨: {str(e)}")
        else:
            raise HTTPException(status_code=500, detail=f"æ›´æ–°æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(e)}")


@router.delete("/{test_case_id}", response_model=UnifiedTestCaseDeleteResponse)
async def delete_unified_test_case(
    test_case_id: int,
    preserve_test_point: bool = Query(False, description="æ˜¯å¦ä¿ç•™æµ‹è¯•ç‚¹ï¼ˆä»…å¯¹æµ‹è¯•ç”¨ä¾‹é˜¶æ®µæœ‰æ•ˆï¼‰"),
    db: Session = Depends(get_db)
):
    """
    åˆ é™¤ç»Ÿä¸€æµ‹è¯•ç”¨ä¾‹
    æ”¯æŒé€»è¾‘åˆ é™¤è¡Œä¸ºï¼š
    - åˆ é™¤æµ‹è¯•ç‚¹æ—¶ï¼Œä¼šåŒæ—¶åˆ é™¤å¯¹åº”çš„æµ‹è¯•ç”¨ä¾‹ï¼ˆå¦‚æžœå·²ç”Ÿæˆï¼‰
    - åˆ é™¤æµ‹è¯•ç”¨ä¾‹æ—¶ï¼Œå¯é€‰æ‹©æ˜¯å¦ä¿ç•™æµ‹è¯•ç‚¹ï¼ˆé€šè¿‡preserve_test_pointå‚æ•°ï¼‰
    """
    try:
        test_case = db.query(UnifiedTestCase).filter(UnifiedTestCase.id == test_case_id).first()

        if not test_case:
            raise HTTPException(status_code=404, detail="æµ‹è¯•ç”¨ä¾‹ä¸å­˜åœ¨")

        deleted_items = []

        # Check if this is a test point or test case
        is_test_point = test_case.is_test_point_stage()
        is_test_case = test_case.is_test_case_stage()

        if is_test_point:
            # Deleting a test point - also delete associated test case if it exists
            # Find and delete the corresponding test case (same case_id but with execution details)
            associated_test_case = db.query(UnifiedTestCase).filter(
                UnifiedTestCase.project_id == test_case.project_id,
                UnifiedTestCase.business_type == test_case.business_type,
                UnifiedTestCase.test_case_id == test_case.test_case_id,
                UnifiedTestCase.steps.is_not(None)  # Test case stage
            ).first()

            if associated_test_case:
                db.delete(associated_test_case)
                deleted_items.append(f"æµ‹è¯•ç”¨ä¾‹: {associated_test_case.name}")

            # Delete the test point itself
            db.delete(test_case)
            deleted_items.append(f"æµ‹è¯•ç‚¹: {test_case.name}")

        elif is_test_case:
            # Deleting a test case
            if preserve_test_point:
                # Option 1: Convert test case back to test point by removing execution details
                test_case.steps = None
                test_case.preconditions = None
                test_case.module = None
                test_case.functional_module = None
                test_case.functional_domain = None
                test_case.remarks = None
                test_case.status = UnifiedTestCaseStatus.DRAFT
                test_case.updated_at = datetime.now()

                deleted_items.append(f"æµ‹è¯•ç”¨ä¾‹å·²è½¬æ¢ä¸ºæµ‹è¯•ç‚¹: {test_case.name}")
            else:
                # Option 2: Delete both test case and corresponding test point
                # Find and delete the corresponding test point (same case_id but without execution details)
                associated_test_point = db.query(UnifiedTestCase).filter(
                    UnifiedTestCase.project_id == test_case.project_id,
                    UnifiedTestCase.business_type == test_case.business_type,
                    UnifiedTestCase.test_case_id == test_case.test_case_id,
                    UnifiedTestCase.steps.is_(None)  # Test point stage
                ).first()

                if associated_test_point:
                    db.delete(associated_test_point)
                    deleted_items.append(f"æµ‹è¯•ç‚¹: {associated_test_point.name}")

                # Delete the test case itself
                db.delete(test_case)
                deleted_items.append(f"æµ‹è¯•ç”¨ä¾‹: {test_case.name}")

        db.commit()

        return UnifiedTestCaseDeleteResponse(message="åˆ é™¤æˆåŠŸ")

    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"åˆ é™¤æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(e)}")


@router.post("/batch", response_model=UnifiedTestCaseBatchResponse)
async def batch_operation_unified_test_cases(
    batch_data: UnifiedTestCaseBatchOperation,
    db: Session = Depends(get_db)
):
    """æ‰¹é‡æ“ä½œç»Ÿä¸€æµ‹è¯•ç”¨ä¾‹"""
    try:
        success_count = 0
        failed_count = 0
        failed_items = []

        test_cases = db.query(UnifiedTestCase).filter(
            UnifiedTestCase.id.in_(batch_data.test_case_ids)
        ).all()

        if batch_data.operation == "delete":
            # æ‰¹é‡åˆ é™¤ - æ”¯æŒé€»è¾‘åˆ é™¤è¡Œä¸º
            for test_case in test_cases:
                try:
                    # Apply the same logical deletion logic as single delete
                    is_test_point = test_case.is_test_point_stage()
                    is_test_case = test_case.is_test_case_stage()

                    if is_test_point:
                        # Deleting a test point - also delete associated test case if it exists
                        associated_test_case = db.query(UnifiedTestCase).filter(
                            UnifiedTestCase.project_id == test_case.project_id,
                            UnifiedTestCase.business_type == test_case.business_type,
                            UnifiedTestCase.test_case_id == test_case.test_case_id,
                            UnifiedTestCase.steps.is_not(None)  # Test case stage
                        ).first()

                        if associated_test_case:
                            db.delete(associated_test_case)

                        # Delete the test point itself
                        db.delete(test_case)

                    elif is_test_case:
                        # For batch delete, we delete both test case and corresponding test point
                        # Find and delete the corresponding test point
                        associated_test_point = db.query(UnifiedTestCase).filter(
                            UnifiedTestCase.project_id == test_case.project_id,
                            UnifiedTestCase.business_type == test_case.business_type,
                            UnifiedTestCase.test_case_id == test_case.test_case_id,
                            UnifiedTestCase.steps.is_(None)  # Test point stage
                        ).first()

                        if associated_test_point:
                            db.delete(associated_test_point)

                        # Delete the test case itself
                        db.delete(test_case)

                    success_count += 1
                except Exception as e:
                    failed_count += 1
                    failed_items.append({
                        "test_case_id": test_case.id,
                        "error": str(e)
                    })

        elif batch_data.operation == "update_status":
            # æ‰¹é‡æ›´æ–°çŠ¶æ€
            if not batch_data.status:
                raise HTTPException(status_code=400, detail="çŠ¶æ€æ›´æ–°æ“ä½œéœ€è¦æä¾›statuså‚æ•°")

            for test_case in test_cases:
                try:
                    test_case.status = batch_data.status.value
                    test_case.updated_at = datetime.now()
                    success_count += 1
                except Exception as e:
                    failed_count += 1
                    failed_items.append({
                        "test_case_id": test_case.id,
                        "error": str(e)
                    })

        elif batch_data.operation == "update_priority":
            # æ‰¹é‡æ›´æ–°ä¼˜å…ˆçº§
            if not batch_data.priority:
                raise HTTPException(status_code=400, detail="ä¼˜å…ˆçº§æ›´æ–°æ“ä½œéœ€è¦æä¾›priorityå‚æ•°")

            for test_case in test_cases:
                try:
                    test_case.priority = batch_data.priority
                    test_case.updated_at = datetime.now()
                    success_count += 1
                except Exception as e:
                    failed_count += 1
                    failed_items.append({
                        "test_case_id": test_case.id,
                        "error": str(e)
                    })

        db.commit()

        return UnifiedTestCaseBatchResponse(
            success_count=success_count,
            failed_count=failed_count,
            failed_items=failed_items
        )

    except HTTPException:
        raise
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"æ‰¹é‡æ“ä½œå¤±è´¥: {str(e)}")


@router.get("/statistics/overview", response_model=UnifiedTestCaseStatistics)
async def get_unified_test_case_statistics(
    project_id: Optional[int] = Query(None, description="é¡¹ç›®ID"),
    business_type: Optional[str] = Query(None, description="ä¸šåŠ¡ç±»åž‹"),
    db: Session = Depends(get_db)
):
    """èŽ·å–ç»Ÿä¸€æµ‹è¯•ç”¨ä¾‹ç»Ÿè®¡ä¿¡æ¯"""
    try:
        query = db.query(UnifiedTestCase)

        if project_id:
            query = query.filter(UnifiedTestCase.project_id == project_id)

        if business_type:
            query = query.filter(UnifiedTestCase.business_type == business_type)

        # æ€»æ•°é‡
        total_count = query.count()

        # æŒ‰é˜¶æ®µç»Ÿè®¡
        test_point_count = query.filter(
            UnifiedTestCase.steps.is_(None)
        ).count()

        test_case_count = total_count - test_point_count

        # æŒ‰çŠ¶æ€ç»Ÿè®¡
        status_stats = db.query(
            UnifiedTestCase.status, func.count(UnifiedTestCase.id)
        ).filter(
            *[UnifiedTestCase.project_id == project_id] if project_id else [],
            *[UnifiedTestCase.business_type == business_type] if business_type else []
        ).group_by(UnifiedTestCase.status).all()

        status_distribution = {
            status.value: count for status, count in status_stats
        }

        # æŒ‰ä¸šåŠ¡ç±»åž‹ç»Ÿè®¡
        business_type_stats = db.query(
            UnifiedTestCase.business_type, func.count(UnifiedTestCase.id)
        ).filter(
            *[UnifiedTestCase.project_id == project_id] if project_id else []
        ).group_by(UnifiedTestCase.business_type).all()

        business_type_distribution = {
            str(bt): count for bt, count in business_type_stats
        }

        # æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡
        priority_stats = db.query(
            UnifiedTestCase.priority, func.count(UnifiedTestCase.id)
        ).filter(
            *[UnifiedTestCase.project_id == project_id] if project_id else [],
            *[UnifiedTestCase.business_type == business_type] if business_type else []
        ).group_by(UnifiedTestCase.priority).all()

        priority_distribution = {
            priority: count for priority, count in priority_stats
        }

        return UnifiedTestCaseStatistics(
            total_count=total_count,
            test_point_count=test_point_count,
            test_case_count=test_case_count,
            status_distribution=status_distribution,
            business_type_distribution=business_type_distribution,
            priority_distribution=priority_distribution
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"èŽ·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}")


# ========================================
# TWO-STAGE GENERATION ENDPOINTS
# ========================================



@router.post("/generate", response_model=UnifiedTestCaseGenerationResponse)
async def generate_unified(
    request: UnifiedTestCaseGenerationRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    """
    Unified generation endpoint supporting both test points and test cases generation.
    - test_points_only: Generate test points for a business type
    - test_cases_only: Generate test cases from existing test points
    """
    try:
        from datetime import datetime
        from ..database.models import GenerationJob, JobStatus, BusinessTypeConfig

        # Validate business type
        business_config = db.query(BusinessTypeConfig).filter(
            BusinessTypeConfig.code == request.business_type.upper(),
            BusinessTypeConfig.is_active == True
        ).first()

        if not business_config:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸šåŠ¡ç±»åž‹ '{request.business_type}' ä¸å­˜åœ¨æˆ–æœªæ¿€æ´»"
            )

        # Validate project exists
        project = db.query(Project).filter(Project.id == request.project_id).first()
        if not project:
            raise HTTPException(status_code=400, detail="é¡¹ç›®ä¸å­˜åœ¨")

        # Validate generation mode and parameters
        if request.generation_mode == "test_cases_only":
            if not request.test_point_ids or len(request.test_point_ids) == 0:
                raise HTTPException(
                    status_code=400,
                    detail="test_cases_onlyæ¨¡å¼éœ€è¦æä¾›test_point_ids"
                )

            # Check if test points exist
            test_points = db.query(UnifiedTestCase).filter(
                UnifiedTestCase.id.in_(request.test_point_ids),
                UnifiedTestCase.business_type == request.business_type.upper(),
                UnifiedTestCase.project_id == request.project_id,
                # Fix: Remove strict steps.is_(None) requirement to allow partially updated test points
                or_(UnifiedTestCase.steps.is_(None), UnifiedTestCase.stage == DatabaseUnifiedTestCaseStage.TEST_POINT)
            ).all()

            if not test_points:
                raise HTTPException(
                    status_code=400,
                    detail="æœªæ‰¾åˆ°æŒ‡å®šçš„æµ‹è¯•ç‚¹"
                )

        # Generate task ID
        task_id = str(uuid.uuid4())

        # Create generation job
        job = GenerationJob(
            id=task_id,
            business_type=request.business_type.upper(),
            status=JobStatus.PENDING,
            project_id=request.project_id,
            generation_mode=request.generation_mode,  # æ·»åŠ generation_modeå­—æ®µ
            created_at=datetime.now()
        )
        db.add(job)
        db.commit()

        # Start background task based on generation mode
        if request.generation_mode == "test_points_only":
            background_tasks.add_task(
                _generate_test_points_background_unified,
                task_id=task_id,
                business_type=request.business_type.upper(),
                project_id=request.project_id,
                additional_context=request.additional_context
            )
            message = f"æµ‹è¯•ç‚¹ç”Ÿæˆä»»åŠ¡å·²åˆ›å»º: {task_id}"
        else:  # test_cases_only
            background_tasks.add_task(
                _generate_test_cases_background_unified,
                task_id=task_id,
                business_type=request.business_type.upper(),
                project_id=request.project_id,
                test_point_ids=request.test_point_ids,
                additional_context=request.additional_context
            )
            message = f"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä»»åŠ¡å·²åˆ›å»º: {task_id}"

        return {
            "generation_job_id": task_id,
            "status": JobStatus.PENDING.value,
            "test_points_generated": 0,
            "test_cases_generated": 0,  # Will be updated when job completes
            "unified_test_cases": None,  # Will be populated when job completes
            "generation_time": None,
            "message": message
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ›å»ºç”Ÿæˆä»»åŠ¡å¤±è´¥: {str(e)}")




@router.get("/generate/status/{task_id}", response_model=Dict[str, Any])
async def get_generation_status_unified(task_id: str, db: Session = Depends(get_db)):
    """
    Get the status of a generation task.
    """
    try:
        from ..database.models import GenerationJob

        job = db.query(GenerationJob).filter(GenerationJob.id == task_id).first()
        if not job:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡æœªæ‰¾åˆ°")

        return {
            "task_id": task_id,
            "status": job.status.value,
            "business_type": _get_business_type_value(job.business_type),
            "project_id": job.project_id,
            "error_message": job.error_message,
            "result_data": job.result_data,
            "created_at": job.created_at.isoformat() if job.created_at else None,
            "completed_at": job.completed_at.isoformat() if job.completed_at else None
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"èŽ·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")



# ========================================
# SYNCHRONOUS GENERATION FUNCTIONS
# ========================================

async def _generate_test_points_sync_unified(
    task_id: str,
    business_type: str,
    project_id: int,
    additional_context: Optional[str] = None,
    db: Session = None
) -> Dict[str, Any]:
    """
    Synchronous test points generation function for debugging.

    Args:
        task_id: Task identifier for tracking
        business_type: Business type for generation
        project_id: Project ID
        additional_context: Additional context for generation
        db: Database session

    Returns:
        Dict containing generation results
    """
    logger.info(f"ðŸš€ Starting synchronous test points generation: task_id={task_id}, business_type={business_type}")

    try:
        # Import required services
        from ..services.generation_service import UnifiedGenerationService
        from ..utils.config import Config

        config = Config()
        generator_service = UnifiedGenerationService(config)

        logger.info(f"Services initialized for task {task_id}")

        # Generate test points using unified generation service
        logger.info(f"Calling generation service for task {task_id}")
        generation_response = generator_service.generate_test_points(
            business_type=business_type,
            additional_context=additional_context or {},
            save_to_database=False,
            project_id=project_id,
            task_id=task_id  # ä¼ å…¥APIç«¯ç‚¹åˆ›å»ºçš„task_id
        )

        logger.info(f"Generation service completed for task {task_id}")
        logger.info(f"Generation response type: {type(generation_response)}")
        logger.info(f"Generation success: {generation_response.success}")

        # Check if generation was successful and extract test points
        if not generation_response.success:
            error_msg = f"æµ‹è¯•ç‚¹ç”Ÿæˆå¤±è´¥: {generation_response.message}"
            logger.error(f"Task {task_id} failed: {error_msg}")
            raise RuntimeError(error_msg)

        # Extract test points list directly from GenerationResponse.result.generated_items
        generation_result = generation_response.result
        if not generation_result or not generation_result.generated_items:
            error_msg = "æµ‹è¯•ç‚¹ç”Ÿæˆç»“æžœä¸ºç©º"
            logger.error(f"Task {task_id} failed: {error_msg}")
            raise RuntimeError(error_msg)

        test_points_list = generation_result.generated_items
        logger.info(f"Successfully obtained {len(test_points_list)} test points from generation service for task {task_id}")

        # Save test points to unified table with simplified logic
        test_point_count = 0
        id_conflict_count = 0
        processed_test_points = []
        created_test_cases = []

        # Use provided database session or create new one
        if db is None:
            from ..database.database import DatabaseManager
            db_manager = DatabaseManager(config)
            with db_manager.get_session() as db:
                result = _save_test_points_to_db(
                    db, test_points_list, business_type, project_id, task_id
                )
                test_point_count, id_conflict_count, processed_test_points, created_test_cases = result
        else:
            result = _save_test_points_to_db(
                db, test_points_list, business_type, project_id, task_id
            )
            test_point_count, id_conflict_count, processed_test_points, created_test_cases = result

        logger.info(f"Task {task_id} completed successfully: {test_point_count} test points saved")

        # Convert created test cases to response format
        unified_test_cases = []
        for test_case in created_test_cases:
            # Convert database stage enum to schema stage enum
            stage = (
                SchemaUnifiedTestCaseStage.TEST_POINT
                if test_case.is_test_point_stage()
                else SchemaUnifiedTestCaseStage.TEST_CASE
            )

            # å‰ç½®æ¡ä»¶çŽ°åœ¨ç›´æŽ¥è¿”å›žå­—ç¬¦ä¸²æ ¼å¼ï¼Œç”±å‰ç«¯è´Ÿè´£è§£æž

            response_data = UnifiedTestCaseResponse(
                id=test_case.id,
                project_id=test_case.project_id,
                business_type=_get_business_type_value(test_case.business_type),
                test_case_id=test_case.test_case_id,
                case_id=test_case.test_case_id,
                name=test_case.name,
                description=test_case.description,
                priority=test_case.priority,
                status=test_case.status,
                stage=stage,
                module=test_case.module,
                functional_module=test_case.functional_module,
                functional_domain=test_case.functional_domain,
                preconditions=test_case.preconditions,  # ç›´æŽ¥è¿”å›žå­—ç¬¦ä¸²æ ¼å¼
                steps=_parse_steps_field(test_case.steps),
                expected_result=test_case.expected_result,
                remarks=test_case.remarks,
                generation_job_id=test_case.generation_job_id,
                entity_order=test_case.entity_order,
                created_at=test_case.created_at,
                updated_at=test_case.updated_at
            )
            unified_test_cases.append(response_data)

        return {
            'test_points_generated': test_point_count,
            'unified_test_cases': unified_test_cases,
            'id_conflicts_resolved': id_conflict_count,
            'processing_details': {
                'total_processed': len(test_points_list),
                'successful': test_point_count,
                'conflicts_resolved': id_conflict_count
            }
        }

    except Exception as e:
        logger.error(f"Error in synchronous test points generation for task {task_id}: {str(e)}", exc_info=True)
        raise RuntimeError(f"åŒæ­¥æµ‹è¯•ç‚¹ç”Ÿæˆå¤±è´¥: {str(e)}")


def _save_test_points_to_db(
    db: Session,
    test_points_list: List[Dict[str, Any]],
    business_type: str,
    project_id: int,
    generation_job_id: str
) -> tuple:
    """
    Save test points to database and return statistics.

    Returns:
        tuple: (test_point_count, id_conflict_count, processed_test_points, created_test_cases)
    """
    test_point_count = 0
    id_conflict_count = 0
    processed_test_points = []
    created_test_cases = []

    for i, point_data in enumerate(test_points_list):
        try:
            # Extract basic data from test point
            original_id = point_data.get('test_case_id') or point_data.get('id') or f'TP{str(i+1).zfill(3)}'
            title = point_data.get('title', point_data.get('name', f'æµ‹è¯•ç‚¹ {i+1}'))
            description = point_data.get('description', '')

            # Ensure ID uniqueness
            unique_id = _ensure_unique_test_case_id(original_id, business_type, project_id, db)

            # Track ID conflicts
            if unique_id != original_id:
                id_conflict_count += 1
                logger.info(f"æµ‹è¯•ç‚¹IDå†²çªå¤„ç†: {original_id} -> {unique_id}")

            # Validate business type using database-driven validation
            validate_business_type_or_400(
                db=db,
                business_type=business_type,
                project_id=project_id
            )

            # Create test point record with clean data
            test_point = UnifiedTestCase(
                project_id=project_id,
                business_type=business_type.upper(),  # Store as uppercase string
                test_case_id=unique_id,
                name=title,
                description=description,
                status=UnifiedTestCaseStatus.DRAFT,
                priority='medium',
                # Test points don't have execution details
                preconditions=None,
                steps=None,
                entity_order=float(i + 1),
                generation_job_id=generation_job_id
            )

            db.add(test_point)
            db.flush()  # Get the ID without committing
            created_test_cases.append(test_point)
            test_point_count += 1

            # Record processing result
            processed_test_points.append({
                'original_id': original_id,
                'final_id': unique_id,
                'was_conflicted': unique_id != original_id,
                'name': title
            })

        except Exception as e:
            logger.error(f"å¤„ç†æµ‹è¯•ç‚¹æ—¶å‡ºé”™ (ç´¢å¼• {i}): {str(e)}")
            continue  # Continue processing other test points

    return test_point_count, id_conflict_count, processed_test_points, created_test_cases


async def _generate_test_cases_sync_unified(
    task_id: str,
    business_type: str,
    project_id: int,
    test_point_ids: List[int],
    additional_context: Optional[str] = None,
    db: Session = None
) -> Dict[str, Any]:
    """
    Synchronous test cases generation function for debugging.
    """
    logger.info(f"ðŸš€ Starting synchronous test cases generation: task_id={task_id}, business_type={business_type}")

    try:
        # This would be implemented similarly to test points generation
        # For now, return a placeholder result
        return {
            'test_cases_generated': 0,
            'unified_test_cases': [],
            'message': 'Test cases generation not implemented in sync mode yet'
        }
    except Exception as e:
        logger.error(f"Error in synchronous test cases generation for task {task_id}: {str(e)}", exc_info=True)
        raise RuntimeError(f"åŒæ­¥æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥: {str(e)}")


# ========================================
# HELPER FUNCTIONS FOR ID CONFLICT HANDLING
# ========================================

def _is_id_exists(test_case_id: str, business_type: str, project_id: int, db) -> bool:
    """
    æ£€æŸ¥test_case_idåœ¨æŒ‡å®šé¡¹ç›®å’Œä¸šåŠ¡ç±»åž‹ä¸­æ˜¯å¦å·²å­˜åœ¨

    Args:
        test_case_id: è¦æ£€æŸ¥çš„æµ‹è¯•ç”¨ä¾‹ID
        business_type: ä¸šåŠ¡ç±»åž‹
        project_id: é¡¹ç›®ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        bool: å¦‚æžœIDå·²å­˜åœ¨è¿”å›žTrueï¼Œå¦åˆ™è¿”å›žFalse
    """
    existing_case = db.query(UnifiedTestCase).filter(
        and_(
            UnifiedTestCase.project_id == project_id,
            UnifiedTestCase.business_type == business_type,
            UnifiedTestCase.test_case_id == test_case_id
        )
    ).first()
    return existing_case is not None


def _ensure_unique_test_case_id(test_case_id: str, business_type: str, project_id: int, db) -> str:
    """
    ç¡®ä¿test_case_idåœ¨é¡¹ç›®å’Œä¸šåŠ¡ç±»åž‹å†…å”¯ä¸€ï¼Œå†²çªæ—¶è‡ªåŠ¨é‡å‘½å

    Args:
        test_case_id: åŽŸå§‹æµ‹è¯•ç”¨ä¾‹ID
        business_type: ä¸šåŠ¡ç±»åž‹
        project_id: é¡¹ç›®ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        str: å”¯ä¸€çš„æµ‹è¯•ç”¨ä¾‹ID
    """
    if not _is_id_exists(test_case_id, business_type, project_id, db):
        return test_case_id

    original_id = test_case_id
    counter = 1

    # å¦‚æžœåŽŸå§‹IDå·²ç»æœ‰æ•°å­—åŽç¼€ï¼Œæå–åŸºç¡€éƒ¨åˆ†
    base_id = original_id
    if '-' in original_id:
        parts = original_id.rsplit('-', 1)
        if len(parts) == 2 and parts[1].isdigit():
            base_id = parts[0]
            counter = int(parts[1]) + 1

    # ç”Ÿæˆæ–°çš„å”¯ä¸€ID
    while True:
        new_id = f"{base_id}-{counter}"
        if not _is_id_exists(new_id, business_type, project_id, db):
            return new_id
        counter += 1


def _batch_check_existing_ids(test_case_ids: List[str], business_type: str, project_id: int, db) -> set:
    """
    æ‰¹é‡æ£€æŸ¥å“ªäº›IDå·²ç»å­˜åœ¨

    Args:
        test_case_ids: è¦æ£€æŸ¥çš„IDåˆ—è¡¨
        business_type: ä¸šåŠ¡ç±»åž‹
        project_id: é¡¹ç›®ID
        db: æ•°æ®åº“ä¼šè¯

    Returns:
        set: å·²å­˜åœ¨çš„IDé›†åˆ
    """
    if not test_case_ids:
        return set()

    existing_ids = db.query(UnifiedTestCase.test_case_id).filter(
        and_(
            UnifiedTestCase.project_id == project_id,
            UnifiedTestCase.business_type == business_type,
            UnifiedTestCase.test_case_id.in_(test_case_ids)
        )
    ).all()

    return {row.test_case_id for row in existing_ids}


# ========================================
# BACKGROUND TASK FUNCTIONS
# ========================================

async def _generate_test_points_background_unified(
    task_id: str,
    business_type: str,
    project_id: int,
    additional_context: Optional[str] = None
):
    """Background task for generating test points in unified system."""
    logger.info(f"ðŸš€ BACKGROUND TASK STARTING: test_points generation for {business_type}, task_id: {task_id}")

    # Use shared dependencies for background tasks
    from ..database.models import GenerationJob, JobStatus, UnifiedTestCase
    from datetime import datetime
    import json
    from .dependencies import get_database_manager, get_unified_generation_service

    # Import AI logger for test_points generation
    try:
        from ..utils.ai_logger import AILoggerManager
    except ImportError:
        AILoggerManager = None
        logger.warning("AILoggerManager not available for test_points generation")

    # Get shared instances to avoid resource duplication
    db_manager = get_database_manager()
    generator_service = get_unified_generation_service()

    # Initialize AI logger for test_points generation
    ai_logger = None
    if AILoggerManager:
        try:
            ai_logger = AILoggerManager.create_logger(task_id, business_type, project_id)
            logger.info(f"âœ… AI Logger initialized successfully for task {task_id}")
        except Exception as e:
            logger.error(f"Failed to initialize AI logger: {e}")
            ai_logger = None

    logger.info(f"âœ… Services and DB manager initialized successfully for task {task_id}")

    # Update job status to running using dedicated database session
    try:
        with db_manager.get_session() as db:
            job = db.query(GenerationJob).filter(GenerationJob.id == task_id).first()
            if job:
                job.status = JobStatus.RUNNING
                job.current_step = 1
                job.step_description = "å¼€å§‹ç”Ÿæˆæµ‹è¯•ç‚¹..."
                db.commit()

        # Generate test points using unified generation service
        logger.info(f"Starting test points generation for business_type: {business_type}, project_id: {project_id}")
        generation_response = generator_service.generate_test_points(
            business_type=business_type,
            additional_context=additional_context or {},
            save_to_database=False,
            project_id=project_id,
            task_id=task_id,
            ai_logger=ai_logger
        )

        # Check if generation was successful and extract test points
        if not generation_response.success:
            raise RuntimeError(f"æµ‹è¯•ç‚¹ç”Ÿæˆå¤±è´¥: {generation_response.message}")

        # Extract test points list directly from GenerationResponse.result.generated_items
        generation_result = generation_response.result
        if not generation_result or not generation_result.generated_items:
            raise RuntimeError("æµ‹è¯•ç‚¹ç”Ÿæˆç»“æžœä¸ºç©º")

        test_points_list = generation_result.generated_items
        logger.info(f"Successfully obtained {len(test_points_list)} test points from generation service")

        # Save test points to unified table with simplified logic
        test_point_count = 0
        id_conflict_count = 0
        processed_test_points = []

        with db_manager.get_session() as db:
            # Process each test point with simplified logic
            for i, point_data in enumerate(test_points_list):
                try:
                    # Extract basic data from test point
                    original_id = point_data.get('test_case_id') or point_data.get('id') or f'TP{str(i+1).zfill(3)}'
                    title = point_data.get('title', point_data.get('name', f'æµ‹è¯•ç‚¹ {i+1}'))
                    description = point_data.get('description', '')

                    # Ensure ID uniqueness
                    unique_id = _ensure_unique_test_case_id(original_id, business_type, project_id, db)

                    # Track ID conflicts
                    if unique_id != original_id:
                        id_conflict_count += 1
                        logger.info(f"æµ‹è¯•ç‚¹IDå†²çªå¤„ç†: {original_id} -> {unique_id}")

                    # Check for duplicate test case by business_type and name
                    existing_test_point = db.query(UnifiedTestCase).filter(
                        UnifiedTestCase.business_type == business_type,
                        UnifiedTestCase.name == title
                    ).first()

                    if existing_test_point:
                        logger.info(f"è·³è¿‡é‡å¤çš„æµ‹è¯•ç‚¹: {title} (ID: {existing_test_point.id})")
                        # Still record in processing results for tracking
                        processed_test_points.append({
                            'original_id': original_id,
                            'final_id': existing_test_point.test_case_id,
                            'was_conflicted': unique_id != original_id,
                            'name': title,
                            'action': 'skipped_duplicate'
                        })
                        continue  # Skip to next test point

                    # Create test point record with clean data
                    test_point = UnifiedTestCase(
                        project_id=project_id,
                        business_type=business_type,
                        test_case_id=unique_id,
                        name=title,
                        description=description,
                        status='draft',
                        priority='medium',
                        # Test points don't have execution details
                        preconditions=None,
                        steps=None,
                        entity_order=float(i + 1),
                        generation_job_id=task_id
                    )

                    db.add(test_point)
                    test_point_count += 1

                    # Record processing result
                    processed_test_points.append({
                        'original_id': original_id,
                        'final_id': unique_id,
                        'was_conflicted': unique_id != original_id,
                        'name': title
                    })

                except Exception as e:
                    logger.error(f"å¤„ç†æµ‹è¯•ç‚¹æ—¶å‡ºé”™ (ç´¢å¼• {i}): {str(e)}")
                    continue  # Continue processing other test points

            # Commit all changes
            db.commit()
            logger.info(f"æµ‹è¯•ç‚¹ç”Ÿæˆå®Œæˆï¼ŒæˆåŠŸä¿å­˜ {test_point_count} ä¸ªæµ‹è¯•ç‚¹")

        # Update job status to completed
        with db_manager.get_session() as db:
            job = db.query(GenerationJob).filter(GenerationJob.id == task_id).first()
            if job:
                job.status = JobStatus.COMPLETED
                job.completed_at = datetime.now()
                job.result_data = json.dumps({
                    "test_points_generated": test_point_count,
                    "project_id": project_id,
                    "id_conflicts_resolved": id_conflict_count,
                    "processing_details": {
                        "total_processed": len(test_points_list),
                        "successful": test_point_count,
                        "conflicts_resolved": id_conflict_count
                    }
                }, ensure_ascii=False)
                db.commit()

                # Finalize AI logging with success
                try:
                    ai_logger.finalize_session(success=True)
                except Exception as log_error:
                    logger.error(f"Failed to finalize AI logging session: {log_error}")

    except Exception as e:
        # Enhanced error logging with full traceback
        logger.error(f"Background task {task_id} failed with error: {str(e)}", exc_info=True)
        logger.error(f"Error type: {type(e).__name__}")
        logger.error(f"Parameters: business_type={business_type}, project_id={project_id}")

        # Update job status to failed with detailed error information using shared dependencies
        try:
            from .dependencies import get_database_manager
            db_manager = get_database_manager()
            with db_manager.get_session() as db:
                job = db.query(GenerationJob).filter(GenerationJob.id == task_id).first()
                if job:
                    job.status = JobStatus.FAILED
                    job.error_message = f"{str(e)} (Type: {type(e).__name__})"[:2000]
                    db.commit()
                    logger.info(f"Updated job {task_id} status to FAILED")
                else:
                    logger.error(f"Job {task_id} not found for error update")
        except Exception as inner_e:
            logger.error(f"Failed to update job status with error: {str(inner_e)}", exc_info=True)
            # Re-throw to make the error visible at the application level
            raise

        # Finalize AI logging with failure
        try:
            if ai_logger:
                ai_logger.finalize_session(success=False, error_message=f"{str(e)} (Type: {type(e).__name__})")
        except Exception as log_error:
            logger.error(f"Failed to finalize AI logging session: {log_error}")


async def _generate_test_cases_background_unified(
    task_id: str,
    business_type: str,
    project_id: int,
    test_point_ids: Optional[List[int]],
    additional_context: Optional[str] = None
):
    """Background task for generating test cases from test points in unified system."""
    logger.info(f"ðŸš€ BACKGROUND TASK STARTING: test_cases generation for {business_type}, task_id: {task_id}")

    # Use shared dependencies for background tasks
    from ..database.models import GenerationJob, JobStatus
    from datetime import datetime
    import json
    from .dependencies import get_database_manager, get_test_case_generator
    from ..utils.ai_logger import AILoggerManager

    # Get shared instances to avoid resource duplication
    db_manager = get_database_manager()
    generator = get_test_case_generator()

    # Create AI logger for this task
    ai_logger = AILoggerManager.create_logger(task_id, business_type, project_id)
    logger.info(f"âœ… AI logger created for task {task_id}: {ai_logger.get_session_path()}")

    logger.info(f"âœ… Test cases generator and DB manager initialized successfully for task {task_id}")

    # Update job status to running using dedicated database session
    try:
        with db_manager.get_session() as db:
            job = db.query(GenerationJob).filter(GenerationJob.id == task_id).first()
            if job:
                job.status = JobStatus.RUNNING
                job.current_step = 1
                job.step_description = "å¼€å§‹åŸºäºŽæµ‹è¯•ç‚¹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹..."
                db.commit()

        # Get test points
        with db_manager.get_session() as db:
            test_points = db.query(UnifiedTestCase).filter(
                UnifiedTestCase.id.in_(test_point_ids) if test_point_ids else True,
                UnifiedTestCase.business_type == business_type,
                UnifiedTestCase.project_id == project_id,
                # Fix: Remove strict steps.is_(None) requirement to allow partially updated test points
                or_(UnifiedTestCase.steps.is_(None), UnifiedTestCase.stage == DatabaseUnifiedTestCaseStage.TEST_POINT)
            ).all()

            if not test_points:
                raise RuntimeError("æœªæ‰¾åˆ°å¯ç”¨çš„æµ‹è¯•ç‚¹")

            # Convert test points to expected format (fixed field mapping)
            test_points_data = {
                "test_points": [
                    {
                        "id": tp.id,
                        "test_case_id": tp.test_case_id,  # Fixed: use test_case_id instead of case_id
                        "title": tp.name,
                        "description": tp.description,
                        "priority": tp.priority
                    }
                    for tp in test_points
                ]
            }

        # Log test points to prompt transformation
        ai_logger.log_test_points_to_prompt({
            "test_points_data": test_points_data,
            "additional_context": additional_context,
            "business_type": business_type,
            "project_id": project_id,
            "test_point_ids": test_point_ids
        })

        # Generate test cases from test points
        # Fix: Pass test_point_ids to enable template variable resolution
        test_cases_data = generator.generate_test_cases_from_external_points(
            business_type=business_type,
            test_points_data=test_points_data,
            additional_context=additional_context or {},
            save_to_db=True,
            project_id=project_id,
            test_point_ids=test_point_ids,
            ai_logger=ai_logger
        )

        if not test_cases_data:
            raise RuntimeError("åŸºäºŽæµ‹è¯•ç‚¹çš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå¤±è´¥")

        # Enhanced data validation and repair
        validator = DataValidatorRepairer()

        # Extract and validate test cases with repair functionality
        if isinstance(test_cases_data, str):
            # If test_cases_data is a string response, parse it first
            json_data, validated_test_cases = JSONExtractor.extract_and_validate_json_response(test_cases_data, validate_and_repair=True, ai_logger=ai_logger)
        else:
            # If test_cases_data is already a dict, validate directly
            validated_test_cases = JSONExtractor.extract_test_cases_from_json(test_cases_data, validate_and_repair=True)

        # Log validation summary
        validation_summary = validator.get_processing_summary()
        logger.info(f"Test case validation complete: {validation_summary['total_cases_processed']} cases, "
                   f"success rate: {validation_summary['success_rate']:.1f}%")

        # Save test cases to unified table with enhanced error handling
        test_case_count = 0
        failed_cases = 0

        with db_manager.get_session() as db:
            # Re-fetch test_points in this session to avoid detached instance issues
            test_points = db.query(UnifiedTestCase).filter(
                UnifiedTestCase.id.in_(test_point_ids) if test_point_ids else True,
                UnifiedTestCase.business_type == business_type,
                UnifiedTestCase.project_id == project_id,
                or_(UnifiedTestCase.steps.is_(None), UnifiedTestCase.stage == DatabaseUnifiedTestCaseStage.TEST_POINT))
            ).all()

            # Use validated test cases instead of raw data
            test_cases_list = validated_test_cases

            for i, case_data in enumerate(test_cases_list):
                try:
                    # Find corresponding test point by database ID (fix: use tp.id instead of tp.test_case_id)
                    test_point_id = case_data.get('test_point_id') or case_data.get('id')
                    logger.info(f"Looking for test point with ID: {test_point_id}")
                    logger.info(f"Available test points: {[tp.id for tp in test_points]}")
                    test_point = next((tp for tp in test_points if tp.id == test_point_id), None)

                    if test_point:
                        # Convert test point to test case by adding execution details
                        # Use validated and repaired data
                        test_point.steps = _serialize_json_field(case_data.get('steps', []))
                        test_point.preconditions = _serialize_json_field(case_data.get('preconditions', []))
                        test_point.module = case_data.get('module', '')
                        test_point.functional_module = case_data.get('functional_module', '')
                        test_point.functional_domain = case_data.get('functional_domain', '')

                        # Enhanced remarks handling - preserve validation info
                        existing_remarks = test_point.remarks or ''
                        validation_remarks = case_data.get('remarks', '')
                        if validation_remarks and '[è‡ªåŠ¨ä¿®å¤]' in validation_remarks:
                            # Add validation info to remarks
                            combined_remarks = f"{existing_remarks} | {validation_remarks}" if existing_remarks else validation_remarks
                            test_point.remarks = combined_remarks
                        else:
                            test_point.remarks = existing_remarks or validation_remarks or ''

                        test_case_count += 1
                        logger.info(f"Successfully converted test point to test case: {test_point.test_case_id}")
                    else:
                        failed_cases += 1
                        logger.warning(f"æœªæ‰¾åˆ°å¯¹åº”çš„æµ‹è¯•ç‚¹ï¼Œè·³è¿‡æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ: {test_point_id}")
                        # Create new test case if test point not found (fallback mechanism)
                        try:
                            case_name = case_data.get('name', f'æ–°ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹ {i+1}')

                            # Check for duplicate test case by business_type and name
                            existing_test_case = db.query(UnifiedTestCase).filter(
                                UnifiedTestCase.business_type == business_type,
                                UnifiedTestCase.name == case_name
                            ).first()

                            if existing_test_case:
                                logger.info(f"è·³è¿‡é‡å¤çš„æµ‹è¯•ç”¨ä¾‹: {case_name} (ID: {existing_test_case.id})")
                                failed_cases += 1
                                continue  # Skip to next test case

                            unique_id = _ensure_unique_test_case_id(case_data.get('test_case_id', f'NEW_TC{str(i+1).zfill(3)}'), business_type, project_id, db)
                            new_test_case = UnifiedTestCase(
                                project_id=project_id,
                                business_type=business_type,
                                test_case_id=unique_id,
                                name=case_name,
                                description=case_data.get('description', ''),
                                status=UnifiedTestCaseStatus.DRAFT,
                                priority=case_data.get('priority', 'medium'),
                                steps=_serialize_json_field(case_data.get('steps', [])),
                                preconditions=_serialize_json_field(case_data.get('preconditions', [])),
                                module=case_data.get('module', ''),
                                functional_module=case_data.get('functional_module', ''),
                                functional_domain=case_data.get('functional_domain', ''),
                                remarks=case_data.get('remarks', '[è‡ªåŠ¨åˆ›å»º] æœªæ‰¾åˆ°å¯¹åº”çš„æµ‹è¯•ç‚¹'),
                                entity_order=float(i + 1),
                                generation_job_id=task_id,
                                stage=DatabaseUnifiedTestCaseStage.test_case
                            )
                            db.add(new_test_case)
                            test_case_count += 1
                            logger.info(f"Created new test case as fallback: {unique_id}")
                        except Exception as create_error:
                            logger.error(f"Failed to create fallback test case: {str(create_error)}")
                            failed_cases += 1

                except Exception as e:
                    failed_cases += 1
                    logger.error(f"å¤„ç†æµ‹è¯•ç”¨ä¾‹æ—¶å‡ºé”™ (ç´¢å¼• {i}): {str(e)}")
                    continue

            db.commit()

            # è®°å½•å¤„ç†ç»“æžœ
            if failed_cases > 0:
                logger.info(f"æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆï¼ŒæˆåŠŸè½¬æ¢ {test_case_count} ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œå¤±è´¥ {failed_cases} ä¸ª")

        # Update job completion with detailed processing results
        with db_manager.get_session() as db:
            job = db.query(GenerationJob).filter(GenerationJob.id == task_id).first()
            if job:
                job.status = JobStatus.COMPLETED
                job.completed_at = datetime.now()
                job.result_data = json.dumps({
                    "test_cases_generated": test_case_count,
                    "test_points_used": len(test_points),
                    "failed_cases": failed_cases,
                    "processing_details": {
                        "total_test_cases": len(test_cases_list),
                        "successful": test_case_count,
                        "failed": failed_cases
                    }
                }, ensure_ascii=False)
                db.commit()

    except Exception as e:
        # Enhanced error logging with full traceback
        logger.error(f"Background test case generation task {task_id} failed with error: {str(e)}", exc_info=True)
        logger.error(f"Error type: {type(e).__name__}")
        logger.error(f"Parameters: business_type={business_type}, project_id={project_id}")

        # Finalize AI logging with failure
        try:
            ai_logger.finalize_session(success=False, error_message=f"{str(e)} (Type: {type(e).__name__})")
        except Exception as log_error:
            logger.error(f"Failed to finalize AI logging session: {log_error}")

        # Update job status to failed with detailed error information using shared dependencies
        try:
            # Use shared db_manager for error handling
            with db_manager.get_session() as db:
                job = db.query(GenerationJob).filter(GenerationJob.id == task_id).first()
                if job:
                    job.status = JobStatus.FAILED
                    job.error_message = f"{str(e)} (Type: {type(e).__name__})"[:2000]
                    db.commit()
        except Exception as inner_e:
            logger.error(f"Failed to update job status with error: {str(inner_e)}", exc_info=True)
            # Don't silently fail - rethrow to make the error visible at the application level
            raise




# è¾…åŠ©å‡½æ•°
def _parse_json_field(field_value: Optional[str]) -> Optional[Any]:
    """è§£æžJSONå­—æ®µ"""
    if field_value is None:
        return None
    try:
        return json.loads(field_value)
    except (json.JSONDecodeError, TypeError):
        return field_value




def _serialize_json_field(field_value: Optional[Any]) -> Optional[str]:
    """åºåˆ—åŒ–JSONå­—æ®µ"""
    if field_value is None:
        return None
    try:
        return json.dumps(field_value, ensure_ascii=False)
    except (TypeError, ValueError):
        return str(field_value) if field_value else None


def _parse_steps_field(field_value: Optional[str]) -> Optional[List[Dict[str, Any]]]:
    """è§£æžstepså­—æ®µï¼Œå¤„ç†JSONå’Œæ—§æ ¼å¼"""
    logger.info(f"ðŸ” Parsing steps field, input length: {len(str(field_value)) if field_value else 0}")

    if field_value is None:
        logger.info("ðŸ“‹ Steps field is None")
        return None

    # é¦–å…ˆå°è¯•è§£æžä¸ºJSON
    try:
        parsed = json.loads(field_value)
        logger.info(f"âœ… JSON parsing successful, type: {type(parsed)}")

        if isinstance(parsed, list):
            logger.info(f"ðŸ“‹ Parsed list with {len(parsed)} items")

            # æ£€æŸ¥æ˜¯å¦æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆæ—§æ ¼å¼ï¼‰
            if all(isinstance(item, str) for item in parsed):
                logger.info("ðŸ”„ Converting string list to step objects")
                # å¤„ç†å­—ç¬¦ä¸²åˆ—è¡¨æ ¼å¼
                steps = []
                for i, item in enumerate(parsed):
                    step_dict = _parse_single_step_string(item)
                    if step_dict:
                        # ç¡®ä¿step_numberæ­£ç¡®è®¾ç½®
                        step_dict['step_number'] = i + 1
                        logger.debug(f"ðŸ“‹ Converted string {i+1} to step: {step_dict.get('action', '')[:50]}...")
                        steps.append(step_dict)
                    else:
                        logger.warning(f"âš ï¸ Failed to parse step string: {item[:50]}...")

                logger.info(f"âœ… Converted {len(steps)} strings to step objects")
                return steps if steps else None
            else:
                # å·²ç»æ˜¯å­—å…¸åˆ—è¡¨æ ¼å¼ï¼ŒéªŒè¯å¹¶å®Œå–„
                logger.info("ðŸ“‹ Processing existing dictionary list")
                validated_steps = []
                for i, step in enumerate(parsed):
                    if isinstance(step, dict):
                        # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
                        validated_step = {
                            "step_number": step.get("step_number", i + 1),
                            "action": step.get("action", step.get("description", "")),
                            "expected": step.get("expected", "")
                        }
                        # ä¿ç•™å…¶ä»–å­—æ®µ
                        for key, value in step.items():
                            if key not in validated_step:
                                validated_step[key] = value
                        validated_steps.append(validated_step)
                        logger.debug(f"ðŸ“‹ Validated step {i+1}: {validated_step.get('action', '')[:50]}...")
                    else:
                        logger.warning(f"âš ï¸ Step {i} is not a dictionary: {step}")

                logger.info(f"âœ… Validated {len(validated_steps)} step objects")
                return validated_steps if validated_steps else None
        else:
            logger.warning(f"âš ï¸ Parsed JSON is not a list: {type(parsed)}")

    except (json.JSONDecodeError, TypeError) as e:
        logger.error(f"âŒ JSON parsing failed: {str(e)}")
        pass

    # å¦‚æžœJSONè§£æžå¤±è´¥ï¼Œå¤„ç†æ—§æ ¼å¼å­—ç¬¦ä¸²
    if isinstance(field_value, str):
        logger.info("ðŸ”„ Processing as plain text string")
        try:
            # æŒ‰è¡Œåˆ†å‰²æ­¥éª¤
            lines = field_value.strip().split('\n')
            steps = []

            for i, line in enumerate(lines):
                line = line.strip()
                if not line:
                    continue

                step_dict = _parse_single_step_string(line)
                if step_dict:
                    # ç¡®ä¿step_numberæ­£ç¡®è®¾ç½®
                    step_dict['step_number'] = i + 1
                    steps.append(step_dict)
                    logger.debug(f"ðŸ“‹ Parsed line {i+1}: {step_dict.get('action', '')[:50]}...")

            logger.info(f"âœ… Parsed {len(steps)} steps from plain text")
            return steps if steps else None
        except Exception as e:
            logger.error(f"âŒ Plain text parsing failed: {str(e)}")
            # å¦‚æžœæ‰€æœ‰è§£æžéƒ½å¤±è´¥ï¼Œè¿”å›žNone
            return None

    logger.warning("âš ï¸ No parsing method succeeded")
    return None


def _merge_steps_with_expected_results(
    steps: Optional[List[Dict[str, Any]]],
    expected_result: Optional[str]
) -> List[Dict[str, Any]]:
    """
    æ™ºèƒ½åˆå¹¶æ­¥éª¤å’Œé¢„æœŸç»“æžœ

    Args:
        steps: è§£æžåŽçš„æ­¥éª¤åˆ—è¡¨
        expected_result: é¢„æœŸç»“æžœå­—ç¬¦ä¸²ï¼ˆæ¢è¡Œåˆ†éš”ï¼‰

    Returns:
        List[Dict[str, Any]]: åˆå¹¶åŽçš„æ­¥éª¤åˆ—è¡¨ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å«actionå’Œexpectedå­—æ®µ
    """
    logger.info(f"ðŸ” Starting merge process with {len(steps) if steps else 0} steps")
    logger.info(f"ðŸŽ¯ Expected result type: {type(expected_result)}, length: {len(str(expected_result)) if expected_result else 0}")

    if not steps:
        logger.info("â„¹ï¸ No steps provided for merging (returning empty list)")
        return []

    # è§£æžé¢„æœŸç»“æžœ
    expected_results = []
    if expected_result:
        logger.info(f"ðŸ“‹ Parsing expected_result: {expected_result[:100]}...")
        try:
            # å¦‚æžœexpected_resultæ˜¯JSONå­—ç¬¦ä¸²æ•°ç»„
            if expected_result.startswith('[') and expected_result.endswith(']'):
                parsed_expected = json.loads(expected_result)
                if isinstance(parsed_expected, list):
                    expected_results = [str(item).strip() for item in parsed_expected if str(item).strip()]
                    logger.info(f"âœ… Parsed JSON expected results: {len(expected_results)} items")
                else:
                    logger.warning(f"âš ï¸ Parsed JSON is not a list: {type(parsed_expected)}")
            else:
                # å¦‚æžœæ˜¯æ™®é€šå­—ç¬¦ä¸²ï¼ŒæŒ‰æ¢è¡Œç¬¦åˆ†å‰²
                expected_results = [item.strip() for item in expected_result.split('\n') if item.strip()]
                logger.info(f"âœ… Parsed text expected results: {len(expected_results)} items")
        except (json.JSONDecodeError, Exception) as e:
            # è§£æžå¤±è´¥æ—¶æŒ‰æ¢è¡Œç¬¦åˆ†å‰²
            logger.error(f"âŒ Failed to parse expected_result: {str(e)}")
            expected_results = [item.strip() for item in str(expected_result).split('\n') if item.strip()]
            logger.info(f"ðŸ”„ Fallback parsed: {len(expected_results)} items")
    else:
        logger.info("ðŸ“‹ No expected_result provided")

    # åˆå¹¶æ­¥éª¤å’Œé¢„æœŸç»“æžœ
    merged_steps = []
    expected_count = len(expected_results)
    steps_with_expected = 0
    steps_without_expected = 0

    for i, step in enumerate(steps):
        # ä¼˜å…ˆä½¿ç”¨æ­¥éª¤è‡ªèº«çš„expectedå­—æ®µ
        step_expected = step.get("expected", "")
        if step_expected:
            steps_with_expected += 1
            logger.debug(f"ðŸ“‹ Step {i+1} already has expected: {step_expected[:50]}...")

        # å¦‚æžœæ­¥éª¤æ²¡æœ‰expectedå­—æ®µï¼Œå°è¯•ä»Žexpected_resultä¸­èŽ·å–
        if not step_expected and i < expected_count:
            step_expected = expected_results[i]
            steps_with_expected += 1
            logger.debug(f"ðŸŽ¯ Assigned expected result to step {i+1}: {step_expected[:50]}...")
        elif not step_expected:
            steps_without_expected += 1
            logger.debug(f"âš ï¸ No expected result for step {i+1}")

        step_data = {
            "step_number": step.get("step_number", i + 1),
            "action": step.get("action", step.get("description", "")),
            "expected": step_expected
        }

        # ä¿ç•™æ­¥éª¤çš„å…¶ä»–å­—æ®µ
        for key, value in step.items():
            if key not in step_data:
                step_data[key] = value

        merged_steps.append(step_data)

    logger.info(f"âœ… Merged {len(steps)} steps with {expected_count} expected results")
    logger.info(f"ðŸ“Š Steps with expected: {steps_with_expected}, without expected: {steps_without_expected}")

    return merged_steps


def _extract_action_and_expected_from_description(description: str) -> tuple[str, str]:
    """
    ä»Žæè¿°ä¸­æå–åŠ¨ä½œå’Œé¢„æœŸç»“æžœ

    Args:
        description: æ­¥éª¤æè¿°æ–‡æœ¬

    Returns:
        tuple: (action, expected) åŠ¨ä½œå’Œé¢„æœŸç»“æžœçš„å…ƒç»„
    """
    if not description:
        return "", ""

    # å°è¯•æŒ‰å¸¸è§çš„åˆ†éš”ç¬¦åˆ†ç¦»åŠ¨ä½œå’Œé¢„æœŸç»“æžœ
    separators = ["é¢„æœŸç»“æžœ:", "æœŸæœ›:", "é¢„æœŸ:", "æœŸæœ›ç»“æžœ:", "Expected:", "Result:"]

    for sep in separators:
        if sep in description:
            parts = description.split(sep, 1)
            if len(parts) == 2:
                action = parts[0].strip()
                expected = parts[1].strip()
                if action and expected:
                    logger.debug(f"Extracted action: '{action}', expected: '{expected}'")
                    return action, expected

    # å¦‚æžœæ²¡æœ‰æ‰¾åˆ°åˆ†éš”ç¬¦ï¼Œæ•´ä¸ªä½œä¸ºåŠ¨ä½œï¼Œé¢„æœŸç»“æžœä¸ºç©º
    logger.debug(f"No separator found, using full description as action: '{description}'")
    return description, ""


def _parse_single_step_string(step_str: str) -> Optional[Dict[str, Any]]:
    """è§£æžå•ä¸ªæ­¥éª¤å­—ç¬¦ä¸²"""
    if not isinstance(step_str, str):
        return None

    step_str = step_str.strip()
    if not step_str:
        return None

    # é¦–å…ˆå°è¯•ç›´æŽ¥è§£æžä¸ºJSON
    try:
        parsed_data = json.loads(step_str)
        if isinstance(parsed_data, dict):
            # ç¡®ä¿è¿”å›žçš„å­—å…¸åŒ…å«å¿…è¦çš„å­—æ®µ
            result = {
                "step_number": parsed_data.get("step_number", 1),
                "description": parsed_data.get("description", parsed_data.get("action", "")),
                "action": parsed_data.get("action", parsed_data.get("description", "")),
                "expected": parsed_data.get("expected", "")
            }
            # ä¿ç•™å…¶ä»–å­—æ®µ
            for key, value in parsed_data.items():
                if key not in result:
                    result[key] = value
            # æ·»åŠ è°ƒè¯•æ—¥å¿—
            logger.debug(f"Parsed JSON step: {result}")
            return result
    except (json.JSONDecodeError, Exception):
        pass

    # å¤„ç†å¸¦ç¼–å·çš„æ­¥éª¤æ ¼å¼ï¼Œå¦‚ "1. æ­¥éª¤æè¿°" æˆ– "1.{\"key\":\"value\"}..."
    if step_str[0].isdigit() and ('.' in step_str or step_str[1:3].isspace() or (len(step_str) > 1 and step_str[1] == '.')):
        # æå–æ­¥éª¤ç¼–å·å’Œæè¿°
        if '.' in step_str:
            parts = step_str.split('.', 1)
            if len(parts) == 2:
                step_num = parts[0].strip()
                step_desc = parts[1].strip()

                # å°è¯•è§£æžæ­¥éª¤æè¿°ä¸­çš„JSONéƒ¨åˆ†
                try:
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«JSONå†…å®¹
                    if '{' in step_desc and '"' in step_desc:
                        # å¯èƒ½æ˜¯æ··åˆæ ¼å¼ï¼š "1.{\"key\":\"value\"}"
                        json_start = step_desc.find('{')
                        if json_start > 0:
                            try:
                                # æå–JSONéƒ¨åˆ†
                                json_part = step_desc[json_start:]
                                parsed_json = json.loads(json_part)
                                text_part = step_desc[:json_start].strip()

                                return {
                                    "step_number": int(step_num),
                                    "description": text_part,
                                    "action": text_part,
                                    "expected": None,
                                    "data": parsed_json
                                }
                            except json.JSONDecodeError:
                                pass

                    # ä»Žæ­¥éª¤æè¿°ä¸­æå–åŠ¨ä½œå’Œé¢„æœŸç»“æžœ
                    action, expected = _extract_action_and_expected_from_description(step_desc)
                    result = {
                        "step_number": int(step_num),
                        "description": action,
                        "action": action,
                        "expected": expected
                    }
                    logger.debug(f"Parsed numbered step: {result}")
                    return result
                except ValueError:
                    # å¦‚æžœæ•°å­—è½¬æ¢å¤±è´¥ï¼Œä½œä¸ºç®€å•æ­¥éª¤å¤„ç†
                    action, expected = _extract_action_and_expected_from_description(step_str)
                    return {
                        "step_number": len(step_str.split()) + 1,
                        "description": action,
                        "action": action,
                        "expected": expected
                    }
            else:
                # æ²¡æœ‰åˆ†å‰²ç¬¦ï¼Œæ•´ä¸ªä½œä¸ºæ­¥éª¤æè¿°
                try:
                    action, expected = _extract_action_and_expected_from_description(step_str)
                    return {
                        "step_number": int(step_str),
                        "description": action,
                        "action": action,
                        "expected": expected
                    }
                except ValueError:
                    action, expected = _extract_action_and_expected_from_description(step_str)
                    return {
                        "step_number": 1,
                        "description": action,
                        "action": action,
                        "expected": expected
                    }
        else:
            # ç¬¬ä¸€ä¸ªå­—ç¬¦ä¸æ˜¯æ•°å­—ï¼Œä½œä¸ºç®€å•æ­¥éª¤å¤„ç†
            action, expected = _extract_action_and_expected_from_description(step_str)
            return {
                "step_number": 1,
                "description": action,
                "action": action,
                "expected": expected
            }
    else:
        # ä¸ä»¥æ•°å­—å¼€å¤´ï¼Œä½œä¸ºç®€å•æ­¥éª¤å¤„ç†
        action, expected = _extract_action_and_expected_from_description(step_str)
        return {
            "step_number": 1,
            "description": action,
            "action": action,
            "expected": expected
        }


def _intelligent_update_test_cases(
    test_cases_data: List[Dict[str, Any]],
    business_type: str,
    project_id: int,
    db,
    generation_job_id: str
) -> Dict[str, Any]:
    """
    æ™ºèƒ½å¢žé‡æ›´æ–°æµ‹è¯•ç”¨ä¾‹ï¼Œé¿å…åˆ é™¤é‡å»ºå¯¼è‡´çš„å…³è”æ•°æ®ä¸¢å¤±

    Args:
        test_cases_data: æ–°çš„æµ‹è¯•ç”¨ä¾‹æ•°æ®åˆ—è¡¨
        business_type: ä¸šåŠ¡ç±»åž‹
        project_id: é¡¹ç›®ID
        db: æ•°æ®åº“ä¼šè¯
        generation_job_id: ç”Ÿæˆä»»åŠ¡ID

    Returns:
        Dict: æ›´æ–°ç»“æžœç»Ÿè®¡
    """
    logger.info(f"å¼€å§‹æ™ºèƒ½å¢žé‡æ›´æ–°æµ‹è¯•ç”¨ä¾‹ï¼Œä¸šåŠ¡ç±»åž‹: {business_type}, é¡¹ç›®: {project_id}")

    updated_count = 0
    created_count = 0
    skipped_count = 0
    error_count = 0

    # èŽ·å–çŽ°æœ‰æµ‹è¯•ç”¨ä¾‹ï¼ˆæŒ‰test_case_idç´¢å¼•ï¼‰
    existing_cases = db.query(UnifiedTestCase).filter(
        UnifiedTestCase.business_type == business_type,
        UnifiedTestCase.project_id == project_id,
        UnifiedTestCase.stage == DatabaseUnifiedTestCaseStage.test_case
    ).all()

    # åˆ›å»ºIDåˆ°çŽ°æœ‰ç”¨ä¾‹çš„æ˜ å°„
    existing_by_id = {case.test_case_id: case for case in existing_cases}

    # å¤„ç†æ–°çš„æµ‹è¯•ç”¨ä¾‹æ•°æ®
    for i, case_data in enumerate(test_cases_data):
        try:
            new_test_case_id = case_data.get('test_case_id')

            if not new_test_case_id:
                logger.warning(f"æµ‹è¯•ç”¨ä¾‹æ•°æ®ç¼ºå°‘test_case_idï¼Œè·³è¿‡å¤„ç†")
                skipped_count += 1
                continue

            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åŒIDçš„æµ‹è¯•ç”¨ä¾‹
            existing_case = existing_by_id.get(new_test_case_id)

            if existing_case:
                # æ‰§è¡Œæ™ºèƒ½æ›´æ–°
                needs_update = False
                update_fields = {}

                # æ¯”è¾ƒå¹¶æ›´æ–°æœ‰å˜åŒ–çš„å­—æ®µ
                field_mappings = {
                    'name': case_data.get('name'),
                    'description': case_data.get('description'),
                    'priority': case_data.get('priority', 'medium'),
                    'module': case_data.get('module', ''),
                    'functional_module': case_data.get('functional_module', ''),
                    'functional_domain': case_data.get('functional_domain', ''),
                    'remarks': case_data.get('remarks', ''),
                    'steps': _serialize_json_field(case_data.get('steps', [])),
                    'preconditions': _serialize_json_field(case_data.get('preconditions', []))
                }

                for field, new_value in field_mappings.items():
                    old_value = getattr(existing_case, field, None)

                    # å¤„ç†JSONå­—æ®µçš„æ¯”è¾ƒ
                    if field in ['steps', 'preconditions']:
                        old_value = _parse_json_field(old_value)

                    if old_value != new_value:
                        update_fields[field] = new_value
                        needs_update = True

                # å¦‚æžœæœ‰å˜åŒ–ï¼Œæ‰§è¡Œæ›´æ–°
                if needs_update:
                    update_fields['updated_at'] = datetime.now()
                    update_fields['generation_job_id'] = generation_job_id

                    # åˆå¹¶å¤‡æ³¨ä¿¡æ¯ï¼Œä¿ç•™æ›´æ–°åŽ†å²
                    if 'remarks' in update_fields:
                        old_remarks = existing_case.remarks or ''
                        new_remarks = update_fields['remarks']
                        if new_remarks and '[è‡ªåŠ¨ä¿®å¤]' in new_remarks:
                            update_fields['remarks'] = f"{old_remarks} | {new_remarks}" if old_remarks else new_remarks

                    for field, value in update_fields.items():
                        setattr(existing_case, field, value)

                    logger.info(f"æ›´æ–°æµ‹è¯•ç”¨ä¾‹: {new_test_case_id}, æ›´æ–°å­—æ®µ: {list(update_fields.keys())}")
                    updated_count += 1
                else:
                    logger.debug(f"æµ‹è¯•ç”¨ä¾‹æ— å˜åŒ–ï¼Œè·³è¿‡: {new_test_case_id}")
                    skipped_count += 1

            else:
                # åˆ›å»ºæ–°æµ‹è¯•ç”¨ä¾‹
                unique_id = _ensure_unique_test_case_id(new_test_case_id, business_type, project_id, db)

                new_case = UnifiedTestCase(
                    project_id=project_id,
                    business_type=business_type,
                    test_case_id=unique_id,
                    name=case_data.get('name', f'æ–°æµ‹è¯•ç”¨ä¾‹ {i+1}'),
                    description=case_data.get('description', ''),
                    status=UnifiedTestCaseStatus.DRAFT,
                    priority=case_data.get('priority', 'medium'),
                    steps=_serialize_json_field(case_data.get('steps', [])),
                    preconditions=_serialize_json_field(case_data.get('preconditions', [])),
                    module=case_data.get('module', ''),
                    functional_module=case_data.get('functional_module', ''),
                    functional_domain=case_data.get('functional_domain', ''),
                    remarks=case_data.get('remarks', '[å¢žé‡æ›´æ–°] æ–°åˆ›å»º'),
                    entity_order=float(i + 1),
                    generation_job_id=generation_job_id,
                    stage=DatabaseUnifiedTestCaseStage.test_case
                )

                db.add(new_case)
                logger.info(f"åˆ›å»ºæ–°æµ‹è¯•ç”¨ä¾‹: {unique_id}")
                created_count += 1

        except Exception as e:
            logger.error(f"å¤„ç†æµ‹è¯•ç”¨ä¾‹æ—¶å‡ºé”™: {str(e)}")
            error_count += 1

    # æäº¤æ‰€æœ‰æ›´æ”¹
    try:
        db.commit()
        logger.info(f"æ™ºèƒ½å¢žé‡æ›´æ–°å®Œæˆ - æ›´æ–°: {updated_count}, åˆ›å»º: {created_count}, è·³è¿‡: {skipped_count}, é”™è¯¯: {error_count}")
    except Exception as commit_error:
        db.rollback()
        logger.error(f"æäº¤æ›´æ”¹æ—¶å‡ºé”™: {str(commit_error)}")
        error_count += len(test_cases_data)

    return {
        'updated_count': updated_count,
        'created_count': created_count,
        'skipped_count': skipped_count,
        'error_count': error_count,
        'total_processed': len(test_cases_data),
        'success_rate': ((updated_count + created_count) / len(test_cases_data) * 100) if test_cases_data else 0
    }


def _batch_update_with_intelligent_mode(
    test_cases_data: List[Dict[str, Any]],
    business_type: str,
    project_id: int,
    db,
    generation_job_id: str
) -> Dict[str, Any]:
    """
    æ‰¹é‡æ™ºèƒ½æ›´æ–°æµ‹è¯•ç”¨ä¾‹çš„åŒ…è£…å‡½æ•°ï¼Œå…¼å®¹çŽ°æœ‰è°ƒç”¨æ–¹å¼

    Args:
        test_cases_data: æµ‹è¯•ç”¨ä¾‹æ•°æ®
        business_type: ä¸šåŠ¡ç±»åž‹
        project_id: é¡¹ç›®ID
        db: æ•°æ®åº“ä¼šè¯
        generation_job_id: ç”Ÿæˆä»»åŠ¡ID

    Returns:
        Dict: æ›´æ–°ç»“æžœç»Ÿè®¡
    """
    return _intelligent_update_test_cases(
        test_cases_data=test_cases_data,
        business_type=business_type,
        project_id=project_id,
        db=db,
        generation_job_id=generation_job_id
    )


@router.post("/test-background", response_model=Dict[str, str])
async def test_background_task(
    background_tasks: BackgroundTasks,
    message: str = "Default test message"
):
    """
    Test endpoint to verify BackgroundTasks functionality.
    This creates a simple background task that logs after a delay.
    """
    task_id = f"test-{uuid.uuid4().hex[:8]}"
    logger.info(f"ðŸ§ª TEST: Creating background task {task_id}")

    background_tasks.add_task(
        _simple_background_test,
        task_id=task_id,
        message=message
    )

    return {
        "message": "Background task created successfully",
        "task_id": task_id,
        "status": "Check logs for background task execution"
    }


async def _simple_background_test(
    task_id: str,
    message: str
):
    """
    Simple background task for testing BackgroundTasks functionality.
    """
    logger.info(f"ðŸ§ª BACKGROUND TASK {task_id} STARTED: message={message}")

    # Simulate some work
    import asyncio
    await asyncio.sleep(2)

    logger.info(f"ðŸ§ª BACKGROUND TASK {task_id} COMPLETED: message={message}")

    # Test database connection from background task
    try:
        from ..database.database import DatabaseManager
        from ..utils.config import Config

        config = Config()
        db_manager = DatabaseManager(config)

        with db_manager.get_session() as db:
            # Simple database query to test connection
            from ..database.models import GenerationJob
            job_count = db.query(GenerationJob).count()
            logger.info(f"ðŸ§ª BACKGROUND TASK {task_id}: Database connection successful, found {job_count} generation jobs")

    except Exception as e:
        logger.error(f"ðŸ§ª BACKGROUND TASK {task_id}: Database connection failed: {str(e)}")
        raise